{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b00cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffb781",
   "metadata": {},
   "source": [
    "# Target high-dim performance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f40455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from juan_first_passage import juan_first_passage\n",
    "#https://rprepo.readthedocs.io/en/latest/reliability_problems.html#sec-rp-300\n",
    "# RP300 14 input variables - gaussian\n",
    "#set_id \t problem_id\n",
    "# 1 \t 15\n",
    "\n",
    "from gfun_213_le_frame import gfun_213_le_frame\n",
    "from le_frame import le_frame\n",
    "import le_frame_rein\n",
    "# https://rprepo.readthedocs.io/en/latest/_modules/gfun_213_le_frame.html#gfun_213_le_frame\n",
    "# set_id\tproblem_id\n",
    "# 1 \t14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e77238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading external dataset file \n",
    "filename_data = 'DataSet_RP300_10e5.sav'\n",
    "dataset = pickle.load(open(filename_data, 'rb'))\n",
    "max_sample = 10**3\n",
    "\n",
    "x_dataset = dataset[0:max_sample, 0:14]\n",
    "y_dataset = dataset[0:max_sample, 14]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_dataset, y_dataset, test_size=0.25, random_state=73)  # create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e932b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_samples = 10**5\n",
    "# x_dataset_2 = np.random.normal(0, 1 , size=(n_samples, 14) )\n",
    "# y_dataset_2 = juan_first_passage(x_dataset_2)\n",
    "\n",
    "## pf estimation with dataset\n",
    "np.sum(y_dataset < 0)/len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0e91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_dataset, y_dataset, train_size=0.9, random_state=73)  # create splits\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32)).view(-1,1)\n",
    "\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e223e",
   "metadata": {},
   "source": [
    "# Creating classes for AutoEncoder (AE) and Variational AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ca5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to create an Autoencoder object\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "         \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(in_dim, 10),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(10, 7),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5, 3),\n",
    "            )\n",
    "         \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(3, 5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5, 7),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(7, 10),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(10, in_dim),\n",
    "            )\n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8123f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to receive an individual sample estimaate of 14 input dim\n",
    "class VAE_small(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.x_hidd = nn.Linear(in_dim, 7)  \n",
    "        self.mu_hidd = nn.Linear(7, 3)  \n",
    "        self.sigma_hidd = nn.Linear(7, 3)\n",
    "        \n",
    "        #decoder         \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "        nn.Linear(3, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(5, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, in_dim),\n",
    "        )\n",
    "    \n",
    "    def enconder(self, x):\n",
    "        h = F.relu(self.x_hidd(x))\n",
    "        mu, sigma = self.mu_hidd(h), F.relu(self.sigma_hidd(h))     #sigma should be positive\n",
    "        return mu, sigma\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.enconder(x)\n",
    "        epsilon = torch.randn_like(sigma)        #reparametrization trick?\n",
    "        z_reparametrized = mu + sigma*epsilon\n",
    "    \n",
    "        x_reconstructed = self.decoder(z_reparametrized)\n",
    "        return x_reconstructed, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "1f782e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to receive the complete distribution of 1000X14 dim\n",
    "class VAE_large(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.hidden = torch.nn.Sequential(\n",
    "        nn.Linear(in_dim, 8000),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(8000, 2000),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(2000, 1000),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(1000, 50),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        \n",
    "        self.mu_hidd = nn.Linear(50, 2)  \n",
    "        self.sigma_hidd = nn.Linear(50, 2)\n",
    "        \n",
    "        #decoder         \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "        nn.Linear(2, 100),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(100, 2000),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(2000, 8000),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(8000, in_dim),\n",
    "        )\n",
    "        \n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.kl = 0\n",
    "        \n",
    "    def enconder(self, x):\n",
    "#         x = torch.flatten(x, start_dim=0)\n",
    "        x_hidd = self.hidden(x)\n",
    "        \n",
    "        mu, sigma = self.mu_hidd(x_hidd), torch.exp(self.sigma_hidd(x_hidd))     #sigma should be positive\n",
    "        return mu, sigma\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.enconder(x)\n",
    "#         epsilon = torch.randn_like(sigma)        #reparametrization trick?\n",
    "        epsilon = self.N.sample(mu.shape)\n",
    "    \n",
    "        z_reparametrized = mu + sigma*epsilon\n",
    "    \n",
    "        x_reconstructed = self.decoder(z_reparametrized)\n",
    "        return x_reconstructed, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "726e9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE_large(\n",
      "  (hidden): Sequential(\n",
      "    (0): Linear(in_features=12600, out_features=8000, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=8000, out_features=2000, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): Linear(in_features=1000, out_features=50, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (mu_hidd): Linear(in_features=50, out_features=2, bias=True)\n",
      "  (sigma_hidd): Linear(in_features=50, out_features=2, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=100, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=100, out_features=2000, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Linear(in_features=2000, out_features=8000, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): Linear(in_features=8000, out_features=12600, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VariationalAutoencoder(14)\n",
    "in_dim = x_train.shape[0] * 14    #complete distribution\n",
    "\n",
    "#model initialization\n",
    "network_VAE = VAE_large(in_dim)   #size of high-dim input space\n",
    "print(network_VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4eb55",
   "metadata": {},
   "source": [
    "Train with a single large data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "3d21108d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [01:29,  1.27it/s, KL=0.00266, recon_loss=0.117]  \n",
      "113it [01:29,  1.27it/s, KL=0.000987, recon_loss=0.0537] \n",
      "113it [01:29,  1.27it/s, KL=0.00344, recon_loss=0.0118]  \n",
      "113it [01:29,  1.26it/s, KL=0.000374, recon_loss=0.0165] \n",
      "113it [01:29,  1.26it/s, KL=9.16e-5, recon_loss=0.00165]  \n",
      "113it [01:29,  1.26it/s, KL=3.26e-5, recon_loss=0.000732] \n",
      "113it [01:29,  1.26it/s, KL=6.79e-6, recon_loss=0.000898]\n",
      "113it [01:29,  1.26it/s, KL=2.09e-6, recon_loss=0.0161]  \n",
      "113it [01:29,  1.26it/s, KL=1.55e-6, recon_loss=0.00138] \n",
      "113it [01:29,  1.26it/s, KL=1.58e-5, recon_loss=0.00023] \n",
      "113it [01:29,  1.26it/s, KL=1.91e-5, recon_loss=0.000283]\n",
      "113it [01:29,  1.26it/s, KL=9.72e-6, recon_loss=0.000643]\n",
      "113it [01:30,  1.25it/s, KL=8.34e-7, recon_loss=0.000458]\n",
      "113it [01:30,  1.25it/s, KL=4.17e-7, recon_loss=7.83e-5] \n",
      "113it [01:30,  1.25it/s, KL=1.67e-5, recon_loss=8.88e-5] \n",
      "113it [01:30,  1.25it/s, KL=1.19e-7, recon_loss=4.14e-5] \n",
      "113it [01:30,  1.26it/s, KL=1.79e-7, recon_loss=0.000223]\n",
      "113it [01:29,  1.26it/s, KL=1.31e-6, recon_loss=0.000118]\n",
      "113it [01:29,  1.26it/s, KL=6.56e-7, recon_loss=0.000477]\n",
      "113it [01:30,  1.25it/s, KL=2.98e-7, recon_loss=5.69e-5] \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_VAE.parameters(), lr = 1e-5)  #Karpathy constant?\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=8, shuffle=False)\n",
    "\n",
    "# test = data.TensorDataset(x_test, y_test)\n",
    "# testloader = data.DataLoader(test, batch_size=32, shuffle=False)\n",
    "\n",
    "num_epochs = 20\n",
    "train_avg_loss = []\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "network_VAE.to(device)\n",
    "\n",
    "# x = x_train\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    loop = tqdm(enumerate(trainloader))\n",
    "    train_losses = []\n",
    "    \n",
    "#     x = torch.flatten(x_train, start_dim=0)   #to output the whole training dataset\n",
    "    \n",
    "    for i, (_ , _) in loop: \n",
    "\n",
    "#         x = x.to(device) # GPU\n",
    "\n",
    "        x_reconstructed, mu, sigma = network_VAE(x)\n",
    "        \n",
    "        reconstruction_loss = criterion(x_reconstructed, x)\n",
    "        KL_div = - torch.sum( 1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2) )\n",
    "\n",
    "        loss = reconstruction_loss + KL_div\n",
    "\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(recon_loss=reconstruction_loss.item(), KL=KL_div.item())\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "\n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "a5e303f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed, mean, sigma = network_VAE(x)\n",
    "\n",
    "# torch.mean(reconstructed, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "63ca97df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9440,  0.7297,  0.5266,  ...,  0.6834, -0.2935,  0.6517],\n",
       "        [ 0.8263,  0.3782, -0.2853,  ..., -2.2855, -0.7539, -0.4024],\n",
       "        [ 1.3038, -1.6090,  0.4643,  ...,  2.7065,  1.8258,  0.7249],\n",
       "        ...,\n",
       "        [ 0.9589,  0.2114, -0.3162,  ..., -0.7215,  0.3331, -1.7005],\n",
       "        [-0.9369, -0.0459, -1.0659,  ...,  0.2128, -0.4306, -0.5368],\n",
       "        [-0.2372, -0.4781, -0.1587,  ..., -0.5914,  0.5585,  1.7806]])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b6995797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0195,  0.0614,  0.0186, -0.0099,  0.0080,  0.0562,  0.0284,  0.0394,\n",
       "        -0.0046, -0.0128,  0.0069, -0.0182,  0.0381,  0.0286],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(reconstructed.view(-1,14), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "2f551365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.1187e-05, 2.6071e-04], grad_fn=<AddBackward0>),\n",
       " tensor([0.9996, 0.9998], grad_fn=<ExpBackward0>))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49696d",
   "metadata": {},
   "source": [
    "Training over a stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ade42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2344it [00:11, 207.37it/s, loss=0.935]\n",
      "2344it [00:10, 222.50it/s, loss=1.03] \n",
      "2344it [00:09, 260.17it/s, loss=0.906]\n",
      "2344it [00:09, 237.74it/s, loss=0.928]\n",
      "1736it [00:07, 201.71it/s, loss=0.996]"
     ]
    }
   ],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_VAE.parameters(), lr = 5e-3)  #Karpathy constant?\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "\n",
    "test = data.TensorDataset(x_test, y_test)\n",
    "testloader = data.DataLoader(test, batch_size=32, shuffle=False)\n",
    "\n",
    "num_epochs = 100\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "network_VAE.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(enumerate(trainloader))\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for i, (x, _) in loop:    #we can omit 'y' value \n",
    "        x = x.to(device) # GPU\n",
    "        \n",
    "        x_reconstructed, mu, sigma = network_VAE(x)\n",
    "        \n",
    "        reconstruction_loss = criterion(x_reconstructed, x)\n",
    "        KL_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "\n",
    "        loss = reconstruction_loss + KL_div\n",
    "        \n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device) # GPU\n",
    "            \n",
    "            x_reconstructed, mu, sigma = network_VAE(x)\n",
    "            KL_div_test = torch.mean(-0.5 *torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2), dim = 1), dim = 0)\n",
    "#             KL_div_test = -0.5 *torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "    \n",
    "            loss_test = criterion(x_reconstructed, x) + KL_div_test\n",
    "            test_losses.append(loss_test)\n",
    "        \n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "\n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "05e92c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_dim, 8)\n",
    "        self.linear2 = nn.Linear(8, 3)     #to output the mean\n",
    "        self.linear3 = nn.Linear(8, 3)     #to output the std. dev.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.linear1(x))   \n",
    "        self.mu =  self.linear2(x)\n",
    "        self.sigma = (self.linear3(x))    #torch.exp(self.linear3(x))    #exponential to ensure positive values?\n",
    "        \n",
    "        z = self.mu + self.sigma*self.N.sample(self.mu.shape)   #reparametrization trick?\n",
    "        z = \n",
    "        \n",
    "        self.kl2 = torch.sum(((self.sigma**2 + self.mu**2)*0.5 + torch.log(1/self.sigma) ) - 1/2\n",
    "        self.kl = (self.sigma**2 + self.mu**2 - torch.log(self.sigma) - 1/2).sum()\n",
    "        \n",
    "        return z\n",
    "    \n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = VariationalEncoder(in_dim)\n",
    "                \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "        nn.Linear(3, 7),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(7, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, in_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9b3ef",
   "metadata": {},
   "source": [
    "Generating samples and splitting the data for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b99bc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[:, 0:14] = x_dataset_2\n",
    "# dataset[:, 14] = y_dataset_2\n",
    "\n",
    "# filename_data = 'DataSet_RP300_10e6.sav'\n",
    "# pickle.dump(dataset, open(filename_data, 'wb'))\n",
    "\n",
    "n_split = int(0.3 * n_samples) #splitting 30 - 70 %\n",
    "\n",
    "x_train = torch.from_numpy(x_dataset[n_split:].astype(np.float32))\n",
    "y_train = torch.from_numpy(y_dataset[n_split:].astype(np.float32)).view(-1,1)\n",
    "\n",
    "x_test = torch.from_numpy(x_dataset[:n_split].astype(np.float32))\n",
    "y_test = torch.from_numpy(y_dataset[:n_split].astype(np.float32)).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717b27f",
   "metadata": {},
   "source": [
    "Setting up losses criterion, optimizer and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_data = 'network_MLP.sav'\n",
    "# pickle.dump(network, open(filename_data, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0858044",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "df317aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_VAE.parameters(), lr = 1e-3, weight_decay = 1e-8)\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=8, shuffle=True)\n",
    "\n",
    "test = data.TensorDataset(x_test, y_test)\n",
    "testloader = data.DataLoader(test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061c48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "network_VAE.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for x, _ in trainloader:    #we can omit 'y' value \n",
    "        x = x.to(device) # GPU\n",
    "        \n",
    "        reconstructed = network_VAE(x)\n",
    "        loss = criterion(reconstructed, x) + network_VAE.encoder.kl\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device) # GPU\n",
    "            \n",
    "            reconstructed = network_VAE(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            test_losses.append(loss)\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "\n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc914113",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2198fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): VariationalEncoder(\n",
      "    (linear1): Linear(in_features=14, out_features=8, bias=True)\n",
      "    (linear2): Linear(in_features=8, out_features=3, bias=True)\n",
      "    (linear3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=5, out_features=7, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Linear(in_features=7, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): Linear(in_features=10, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VariationalAutoencoder(14)\n",
    "\n",
    "#model initialization\n",
    "network_VAE = VariationalAutoencoder(14)   #size of high-dim input space\n",
    "print(network_VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8681cc",
   "metadata": {},
   "source": [
    "# Training AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model initialization\n",
    "network_AE = AE(14)   #size of high-dim input space\n",
    "print(network_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_AE.parameters(), lr = 1e-3, weight_decay = 1e-8)\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "\n",
    "test = data.TensorDataset(x_test, y_test)\n",
    "testloader = data.DataLoader(test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f88a7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4802, -1.2490,  1.6753, -0.8688,  0.3083, -2.2746,  1.3434, -0.4604,\n",
       "           0.1526, -0.0868,  0.1575,  1.5750,  0.3654, -0.9355],\n",
       "         [ 0.2175, -0.9641,  1.0017,  1.2289, -0.1299,  1.5098, -0.3451, -0.0402,\n",
       "           0.2424,  1.2978,  2.0415, -1.0528,  0.1025,  0.4606],\n",
       "         [ 1.5176, -0.9983,  0.4086,  0.4517,  1.3321, -1.0839,  0.4787, -0.2173,\n",
       "           0.8907,  0.4958, -0.0428,  0.0357, -1.0243, -0.8162],\n",
       "         [ 0.0281,  0.3725, -0.7837,  0.6350,  0.2843, -0.2053,  0.0142, -0.0343,\n",
       "          -1.5186,  2.1642, -0.9725,  0.7644,  0.1559,  0.3771],\n",
       "         [-0.6112, -0.5334, -0.3920, -0.2442,  1.3271,  0.9063, -0.8039, -1.9579,\n",
       "           0.6331,  0.4457, -1.1984,  1.7865, -0.6967, -0.6974],\n",
       "         [-0.9532,  0.7419,  0.2524, -0.6380,  0.4273, -2.0657, -1.0202,  0.6986,\n",
       "           2.0891, -0.0048, -1.0344,  0.1775,  0.1751,  0.8058],\n",
       "         [-2.6814,  0.7395,  0.6061, -0.9709, -1.6633,  1.0674, -1.2036, -1.3949,\n",
       "           0.2058, -0.6143, -0.3429,  0.1286, -1.4696,  0.9434],\n",
       "         [-0.3235,  0.3190, -0.5519,  0.2493,  1.1185,  0.9876,  1.5913,  0.5084,\n",
       "           0.7252,  0.9441,  0.4086, -1.1879,  0.1710, -0.2952]]),\n",
       " False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _ in trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d92427",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "network_AE.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for _, _ in trainloader:    #we can omit 'y' value \n",
    "        x = x.to(device)\n",
    "        \n",
    "        reconstructed = network_AE(x)\n",
    "        loss = criterion(reconstructed, x)\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for _, _ in testloader:\n",
    "#             x = x.to(device)\n",
    "            \n",
    "            reconstructed = network_AE(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            test_losses.append(loss)\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "    \n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "network_AE.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for x, _ in trainloader:    #we can omit 'y' value \n",
    "        x = x.to(device)\n",
    "        \n",
    "        reconstructed = network_AE(x)\n",
    "        loss = criterion(reconstructed, x)\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            reconstructed = network_AE(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            test_losses.append(loss)\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "    \n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = 1e-3, batchsize=128, weight_decay = 1e-8\n",
    "#latent = 5\n",
    "\n",
    "# (encoder): Sequential(\n",
    "#     (0): Linear(in_features=14, out_features=12, bias=True)\n",
    "#     (1): LeakyReLU(negative_slope=0.1)\n",
    "#     (2): Linear(in_features=12, out_features=10, bias=True)\n",
    "#     (3): LeakyReLU(negative_slope=0.1)\n",
    "#     (4): Linear(in_features=10, out_features=7, bias=True)\n",
    "#     (5): LeakyReLU(negative_slope=0.1)\n",
    "#     (6): Linear(in_features=7, out_features=5, bias=True)\n",
    "#   )\n",
    "\n",
    "# fig, axs = plt.subplots(1, 1)\n",
    "# axs.set_title('Training Loss')\n",
    "# axs.plot(train_avg_loss)\n",
    "# axs.plot(test_avg_loss)\n",
    "# axs.set_xlabel('Iterations')\n",
    "# axs.set_ylabel('Loss (MSELoss)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c48c8",
   "metadata": {},
   "source": [
    "Pf estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5abb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading network\n",
    "# filename_data = 'network_MLP.sav'\n",
    "# network = pickle.load(open(filename_data, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 200\n",
    "samplex = torch.from_numpy(x_dataset[point].astype(np.float32)).to(device)\n",
    "\n",
    "y_dataset[point], network(samplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_dataset < 0)/len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 10**6\n",
    "# x_pred = np.random.rand(n_pred, 14)\n",
    "x_pred = np.random.normal(0, 1 , size=(n_samples, 14) )\n",
    "\n",
    "x_pred = torch.from_numpy(x_pred.astype(np.float32)).to(device)\n",
    "\n",
    "# x_pred = torch.randn(n_pred, 14, device=device)\n",
    "\n",
    "y_pred = network(x_pred)   #MLP\n",
    "\n",
    "np.sum(y_pred.cpu().detach().numpy() < 0)\n",
    "\n",
    "# np.sum(y_pred < 0)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dbd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(y_pred.cpu().detach().numpy())\n",
    "plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_AE = network_AE.to('cpu')\n",
    "\n",
    "y_pred_AE = network_AE.encoder(x_pred)\n",
    "\n",
    "y_pred_AE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_var = 2\n",
    "counts, bins = np.histogram(y_pred_AE[:, lat_var].cpu().detach().numpy())\n",
    "plt.stairs(counts, bins)\n",
    "\n",
    "np.sum(y_pred.cpu().detach().numpy() < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = y_pred < 0\n",
    "negative.sum(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 10\n",
    "samplex = x_dataset[point]\n",
    "sampley = y_dataset[point]\n",
    "\n",
    "samplex_torch = torch.from_numpy(x_dataset[point].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sampley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.from_numpy(np.array(sampley)) - network(samplex_torch))**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
