{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1b00cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffb781",
   "metadata": {},
   "source": [
    "# Target high-dim performance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f40455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from juan_first_passage import juan_first_passage\n",
    "#https://rprepo.readthedocs.io/en/latest/reliability_problems.html#sec-rp-300\n",
    "# RP300 14 input variables - gaussian\n",
    "#set_id \t problem_id\n",
    "# 1 \t 15\n",
    "\n",
    "from gfun_213_le_frame import gfun_213_le_frame\n",
    "from le_frame import le_frame\n",
    "import le_frame_rein\n",
    "# https://rprepo.readthedocs.io/en/latest/_modules/gfun_213_le_frame.html#gfun_213_le_frame\n",
    "# set_id\tproblem_id\n",
    "# 1 \t14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e223e",
   "metadata": {},
   "source": [
    "# Creating classes for AutoEncoder (AE) and Variational AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ca5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to create an Autoencoder object\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "         \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(in_dim, 10),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(10, 7),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(7, 5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5, 3),\n",
    "            )\n",
    "         \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(3, 5),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5, 7),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(7, 10),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(10, in_dim),\n",
    "            )\n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "8123f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder_1(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.x_hidd = nn.Linear(in_dim, 7)  \n",
    "        self.mu_hidd = nn.Linear(7, 3)  \n",
    "        self.sigma_hidd = nn.Linear(7, 3)\n",
    "        \n",
    "        #decoder         \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "        nn.Linear(3, 5),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(5, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, in_dim),\n",
    "        )\n",
    "    \n",
    "    def enconder(self, x):\n",
    "        h = F.relu(self.x_hidd(x))\n",
    "        mu, sigma = self.mu_hidd(h), self.sigma_hidd(h)\n",
    "        return mu, sigma\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.enconder(x)\n",
    "        epsilon = torch.randn_like(sigma)        #reparametrization trick?\n",
    "        z_reparametrized = mu + sigma*epsilon\n",
    "    \n",
    "        x_reconstructed = self.decoder(z_reparametrized)\n",
    "        return x_reconstructed, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "726e9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder_1(\n",
      "  (x_hidd): Linear(in_features=14, out_features=7, bias=True)\n",
      "  (mu_hidd): Linear(in_features=7, out_features=3, bias=True)\n",
      "  (sigma_hidd): Linear(in_features=7, out_features=3, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=10, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VariationalAutoencoder(14)\n",
    "\n",
    "#model initialization\n",
    "network_VAE = VariationalAutoencoder_1(14)   #size of high-dim input space\n",
    "print(network_VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ade42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2344it [00:11, 207.37it/s, loss=0.935]\n",
      "2344it [00:10, 222.50it/s, loss=1.03] \n",
      "2344it [00:09, 260.17it/s, loss=0.906]\n",
      "2344it [00:09, 237.74it/s, loss=0.928]\n",
      "1736it [00:07, 201.71it/s, loss=0.996]"
     ]
    }
   ],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_VAE.parameters(), lr = 5e-3)  #Karpathy constant?\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "\n",
    "test = data.TensorDataset(x_test, y_test)\n",
    "testloader = data.DataLoader(test, batch_size=32, shuffle=False)\n",
    "\n",
    "num_epochs = 100\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "network_VAE.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(enumerate(trainloader))\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for i, (x, _) in loop:    #we can omit 'y' value \n",
    "        x = x.to(device) # GPU\n",
    "        \n",
    "        x_reconstructed, mu, sigma = network_VAE(x)\n",
    "        \n",
    "        reconstruction_loss = criterion(x_reconstructed, x)\n",
    "        KL_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "\n",
    "        loss = reconstruction_loss + KL_div\n",
    "        \n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device) # GPU\n",
    "            \n",
    "            x_reconstructed, mu, sigma = network_VAE(x)\n",
    "            KL_div_test = torch.mean(-0.5 *torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2), dim = 1), dim = 0)\n",
    "#             KL_div_test = -0.5 *torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "    \n",
    "            loss_test = criterion(x_reconstructed, x) + KL_div_test\n",
    "            test_losses.append(loss_test)\n",
    "        \n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "\n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "05e92c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_dim, 8)\n",
    "        self.linear2 = nn.Linear(8, 3)     #to output the mean\n",
    "        self.linear3 = nn.Linear(8, 3)     #to output the std. dev.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.linear1(x))   \n",
    "        self.mu =  self.linear2(x)\n",
    "        self.sigma = (self.linear3(x))    #torch.exp(self.linear3(x))    #exponential to ensure positive values?\n",
    "        \n",
    "        z = self.mu + self.sigma*self.N.sample(self.mu.shape)   #reparametrization trick?\n",
    "        z = \n",
    "        \n",
    "        self.kl2 = torch.sum(((self.sigma**2 + self.mu**2)*0.5 + torch.log(1/self.sigma) ) - 1/2\n",
    "        self.kl = (self.sigma**2 + self.mu**2 - torch.log(self.sigma) - 1/2).sum()\n",
    "        \n",
    "        return z\n",
    "    \n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = VariationalEncoder(in_dim)\n",
    "                \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "        nn.Linear(3, 7),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(7, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, in_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9504de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): VariationalEncoder(\n",
      "    (linear1): Linear(in_features=14, out_features=8, bias=True)\n",
      "    (linear2): Linear(in_features=8, out_features=3, bias=True)\n",
      "    (linear3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=5, out_features=7, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Linear(in_features=7, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): Linear(in_features=10, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network_test = VariationalAutoencoder(14)\n",
    "print(network_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "818abc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,_ = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "28fe82f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_23640/1334494106.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mVariationalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_23640/2970625115.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_dim)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariationalEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: empty(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2"
     ]
    }
   ],
   "source": [
    "VariationalEncoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "eeaddadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_latent = network_test.encoder.forward(x)\n",
    "\n",
    "x_reconstr = network_test.decoder(z_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "41c36cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.4473, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_test.encoder.kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "030e8780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9573, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_test.encoder.kl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "04153b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dist = torch.log((network_test.encoder.mu) + (network_test.encoder.sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9a21d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = network_test.encoder.mu + network_test.encoder.sigma*network_test.encoder.N.sample(network_test.encoder.mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b0f9f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dist = network_test.encoder.N.sample(network_test.encoder.mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "fbfaef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "5e8df5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2029, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sum(target_dist, dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "55f49a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2029, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(target_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "0b72f0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2824, -0.1817,  0.4688])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(target_dist, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "31aba76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kl = nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9e7bd769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3836, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_kl(input_dist, target_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f309db8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2134, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(x_reconstr, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e45a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeL1 = network_VAE.encoder.linear1(x_sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980383eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = torch.from_numpy(x_dataset[0].astype(np.float32))\n",
    "\n",
    "x_sample = x_sample.to(device)\n",
    "\n",
    "network_VAE.encoder(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c779ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_dataset[n_split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8108ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.distributions.Normal(0, 1).sample(shapeL1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VariationalAutoencoder(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9b3ef",
   "metadata": {},
   "source": [
    "Generating samples and splitting the data for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e932b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 10**5\n",
    "\n",
    "# x_dataset_2 = np.random.normal(0, 1 , size=(n_samples, 14) )\n",
    "\n",
    "# y_dataset_2 = juan_first_passage(x_dataset_2)\n",
    "\n",
    "## pf estimation with dataset\n",
    "np.sum(y_dataset < 0)/len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "14e77238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading external dataset file \n",
    "filename_data = 'DataSet_RP300_10e5.sav'\n",
    "dataset = pickle.load(open(filename_data, 'rb'))\n",
    "x_dataset = dataset[:, 0:14]\n",
    "y_dataset = dataset[:, 14]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_dataset, y_dataset, test_size=0.25, random_state=73)  # create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b99bc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[:, 0:14] = x_dataset_2\n",
    "# dataset[:, 14] = y_dataset_2\n",
    "\n",
    "# filename_data = 'DataSet_RP300_10e6.sav'\n",
    "# pickle.dump(dataset, open(filename_data, 'wb'))\n",
    "\n",
    "n_split = int(0.3 * n_samples) #splitting 30 - 70 %\n",
    "\n",
    "x_train = torch.from_numpy(x_dataset[n_split:].astype(np.float32))\n",
    "y_train = torch.from_numpy(y_dataset[n_split:].astype(np.float32)).view(-1,1)\n",
    "\n",
    "x_test = torch.from_numpy(x_dataset[:n_split].astype(np.float32))\n",
    "y_test = torch.from_numpy(y_dataset[:n_split].astype(np.float32)).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5c0e91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_dataset, y_dataset, test_size=0.25, random_state=73)  # create splits\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32)).view(-1,1)\n",
    "\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717b27f",
   "metadata": {},
   "source": [
    "Setting up losses criterion, optimizer and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_data = 'network_MLP.sav'\n",
    "# pickle.dump(network, open(filename_data, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0858044",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2198fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): VariationalEncoder(\n",
      "    (linear1): Linear(in_features=14, out_features=8, bias=True)\n",
      "    (linear2): Linear(in_features=8, out_features=3, bias=True)\n",
      "    (linear3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=5, out_features=7, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Linear(in_features=7, out_features=10, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): Linear(in_features=10, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VariationalAutoencoder(14)\n",
    "\n",
    "#model initialization\n",
    "network_VAE = VariationalAutoencoder(14)   #size of high-dim input space\n",
    "print(network_VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "df317aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_VAE.parameters(), lr = 1e-3, weight_decay = 1e-8)\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=8, shuffle=True)\n",
    "\n",
    "test = data.TensorDataset(x_test, y_test)\n",
    "testloader = data.DataLoader(test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061c48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "network_VAE.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for x, _ in trainloader:    #we can omit 'y' value \n",
    "        x = x.to(device) # GPU\n",
    "        \n",
    "        reconstructed = network_VAE(x)\n",
    "        loss = criterion(reconstructed, x) + network_VAE.encoder.kl\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device) # GPU\n",
    "            \n",
    "            reconstructed = network_VAE(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            test_losses.append(loss)\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "\n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc914113",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8681cc",
   "metadata": {},
   "source": [
    "# Training AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model initialization\n",
    "network_AE = AE(14)   #size of high-dim input space\n",
    "print(network_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the MSE loss as criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# we create an instance of the SGD class that will make the updates for us\n",
    "# optimizer = optim.SGD(params= network.parameters(), lr=.1)\n",
    "optimizer = optim.Adam(params= network_AE.parameters(), lr = 1e-3, weight_decay = 1e-8)\n",
    "\n",
    "train = data.TensorDataset(x_train, y_train)\n",
    "trainloader = data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "\n",
    "test = data.TensorDataset(x_test, y_test)\n",
    "testloader = data.DataLoader(test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f88a7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4802, -1.2490,  1.6753, -0.8688,  0.3083, -2.2746,  1.3434, -0.4604,\n",
       "           0.1526, -0.0868,  0.1575,  1.5750,  0.3654, -0.9355],\n",
       "         [ 0.2175, -0.9641,  1.0017,  1.2289, -0.1299,  1.5098, -0.3451, -0.0402,\n",
       "           0.2424,  1.2978,  2.0415, -1.0528,  0.1025,  0.4606],\n",
       "         [ 1.5176, -0.9983,  0.4086,  0.4517,  1.3321, -1.0839,  0.4787, -0.2173,\n",
       "           0.8907,  0.4958, -0.0428,  0.0357, -1.0243, -0.8162],\n",
       "         [ 0.0281,  0.3725, -0.7837,  0.6350,  0.2843, -0.2053,  0.0142, -0.0343,\n",
       "          -1.5186,  2.1642, -0.9725,  0.7644,  0.1559,  0.3771],\n",
       "         [-0.6112, -0.5334, -0.3920, -0.2442,  1.3271,  0.9063, -0.8039, -1.9579,\n",
       "           0.6331,  0.4457, -1.1984,  1.7865, -0.6967, -0.6974],\n",
       "         [-0.9532,  0.7419,  0.2524, -0.6380,  0.4273, -2.0657, -1.0202,  0.6986,\n",
       "           2.0891, -0.0048, -1.0344,  0.1775,  0.1751,  0.8058],\n",
       "         [-2.6814,  0.7395,  0.6061, -0.9709, -1.6633,  1.0674, -1.2036, -1.3949,\n",
       "           0.2058, -0.6143, -0.3429,  0.1286, -1.4696,  0.9434],\n",
       "         [-0.3235,  0.3190, -0.5519,  0.2493,  1.1185,  0.9876,  1.5913,  0.5084,\n",
       "           0.7252,  0.9441,  0.4086, -1.1879,  0.1710, -0.2952]]),\n",
       " False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _ in trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d92427",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "network_AE.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for _, _ in trainloader:    #we can omit 'y' value \n",
    "        x = x.to(device)\n",
    "        \n",
    "        reconstructed = network_AE(x)\n",
    "        loss = criterion(reconstructed, x)\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for _, _ in testloader:\n",
    "#             x = x.to(device)\n",
    "            \n",
    "            reconstructed = network_AE(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            test_losses.append(loss)\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "    \n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "network_AE.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for x, _ in trainloader:    #we can omit 'y' value \n",
    "        x = x.to(device)\n",
    "        \n",
    "        reconstructed = network_AE(x)\n",
    "        loss = criterion(reconstructed, x)\n",
    "        train_losses.append(loss.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "\n",
    "        for x, _ in testloader:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            reconstructed = network_AE(x)\n",
    "            loss = criterion(reconstructed, x)\n",
    "            test_losses.append(loss)\n",
    "\n",
    "    train_avg_loss.append(sum(train_losses)/len(train_losses))\n",
    "    test_avg_loss.append(sum(test_losses)/len(test_losses))\n",
    "    \n",
    "# Move everything back to the CPU\n",
    "train_avg_loss = torch.tensor(train_avg_loss, device = 'cpu')\n",
    "test_avg_loss = torch.tensor(test_avg_loss, device = 'cpu')\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.set_title('Training Loss')\n",
    "axs.plot(train_avg_loss)\n",
    "axs.plot(test_avg_loss)\n",
    "axs.set_xlabel('Iterations')\n",
    "axs.set_ylabel('Loss (MSELoss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = 1e-3, batchsize=128, weight_decay = 1e-8\n",
    "#latent = 5\n",
    "\n",
    "# (encoder): Sequential(\n",
    "#     (0): Linear(in_features=14, out_features=12, bias=True)\n",
    "#     (1): LeakyReLU(negative_slope=0.1)\n",
    "#     (2): Linear(in_features=12, out_features=10, bias=True)\n",
    "#     (3): LeakyReLU(negative_slope=0.1)\n",
    "#     (4): Linear(in_features=10, out_features=7, bias=True)\n",
    "#     (5): LeakyReLU(negative_slope=0.1)\n",
    "#     (6): Linear(in_features=7, out_features=5, bias=True)\n",
    "#   )\n",
    "\n",
    "# fig, axs = plt.subplots(1, 1)\n",
    "# axs.set_title('Training Loss')\n",
    "# axs.plot(train_avg_loss)\n",
    "# axs.plot(test_avg_loss)\n",
    "# axs.set_xlabel('Iterations')\n",
    "# axs.set_ylabel('Loss (MSELoss)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c48c8",
   "metadata": {},
   "source": [
    "Pf estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5abb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading network\n",
    "# filename_data = 'network_MLP.sav'\n",
    "# network = pickle.load(open(filename_data, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 200\n",
    "samplex = torch.from_numpy(x_dataset[point].astype(np.float32)).to(device)\n",
    "\n",
    "y_dataset[point], network(samplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_dataset < 0)/len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 10**6\n",
    "# x_pred = np.random.rand(n_pred, 14)\n",
    "x_pred = np.random.normal(0, 1 , size=(n_samples, 14) )\n",
    "\n",
    "x_pred = torch.from_numpy(x_pred.astype(np.float32)).to(device)\n",
    "\n",
    "# x_pred = torch.randn(n_pred, 14, device=device)\n",
    "\n",
    "y_pred = network(x_pred)   #MLP\n",
    "\n",
    "np.sum(y_pred.cpu().detach().numpy() < 0)\n",
    "\n",
    "# np.sum(y_pred < 0)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dbd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(y_pred.cpu().detach().numpy())\n",
    "plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_AE = network_AE.to('cpu')\n",
    "\n",
    "y_pred_AE = network_AE.encoder(x_pred)\n",
    "\n",
    "y_pred_AE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_var = 2\n",
    "counts, bins = np.histogram(y_pred_AE[:, lat_var].cpu().detach().numpy())\n",
    "plt.stairs(counts, bins)\n",
    "\n",
    "np.sum(y_pred.cpu().detach().numpy() < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = y_pred < 0\n",
    "negative.sum(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 10\n",
    "samplex = x_dataset[point]\n",
    "sampley = y_dataset[point]\n",
    "\n",
    "samplex_torch = torch.from_numpy(x_dataset[point].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sampley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.from_numpy(np.array(sampley)) - network(samplex_torch))**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
