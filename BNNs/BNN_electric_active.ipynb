{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff0bf73",
   "metadata": {},
   "source": [
    "# BNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed3ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_models import Pbnn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from doepy import build\n",
    "import pickle\n",
    "from scipy.stats import norm, uniform, lognorm\n",
    "from scipy.stats import qmc    #for sobol seq. (LHS is also available in this QuasiMC library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bf0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LStates.g11D_electric import example_electric\n",
    "\n",
    "function = example_electric\n",
    "\n",
    "def convert_lognormal(mean_ln, std_ln):\n",
    "    gaussian_param = np.zeros(2)\n",
    "\n",
    "    SigmaLogNormal = np.sqrt( np.log(1+(std_ln/mean_ln)**2))\n",
    "    MeanLogNormal = np.log( mean_ln ) - SigmaLogNormal**2/2\n",
    "\n",
    "    gaussian_param[0] = MeanLogNormal\n",
    "    gaussian_param[1] = SigmaLogNormal\n",
    "\n",
    "    return gaussian_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f4825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = L (m) mean=4.2    cov=0.10   lognormal/R>0\n",
    "x1_mean = 4.20\n",
    "x1_std = x1_mean * 0.10\n",
    "normal_std_1 = np.sqrt(np.log(1 + (x1_std/x1_mean)**2))\n",
    "normal_mean_1 = np.log(x1_mean) - normal_std_1**2 / 2\n",
    "\n",
    "# X2 = h (m) mean=0.02    cov=0.10 lognormal /R>0\n",
    "x2_mean = 0.02\n",
    "x2_std = x2_mean * 0.1\n",
    "normal_std_2 = np.sqrt(np.log(1 + (x2_std/x2_mean)**2))\n",
    "normal_mean_2 = np.log(x2_mean) - normal_std_2**2 / 2\n",
    "\n",
    "# X3 = d (m) mean=0.001  cov=0.05 lognormal /R>0\n",
    "x3_mean = 0.001\n",
    "x3_std = x3_mean * 0.05\n",
    "normal_std_3 = np.sqrt(np.log(1 + (x3_std/x3_mean)**2))\n",
    "normal_mean_3 = np.log(x3_mean) - normal_std_3**2 / 2\n",
    "\n",
    "# X4 = ZL () mean=1000    cov=0.20 lognormal /R>0\n",
    "x4_mean = 1000\n",
    "x4_std = x4_mean * 0.2\n",
    "normal_std_4 = np.sqrt(np.log(1 + (x4_std/x4_mean)**2))\n",
    "normal_mean_4 = np.log(x4_mean) - normal_std_4**2 / 2\n",
    "\n",
    "# X5 = Z0 () mean=50   cov=0.05 lognormal /R>0\n",
    "x5_mean = 50\n",
    "x5_std = x5_mean * 0.05\n",
    "normal_std_5 = np.sqrt(np.log(1 + (x5_std/x5_mean)**2))\n",
    "normal_mean_5 = np.log(x5_mean) - normal_std_5**2 / 2\n",
    "\n",
    "# X6 = ae (V/m) mean=1  cov=0.20 lognormal /R>0\n",
    "x6_mean = 1\n",
    "x6_std = x6_mean * 0.2\n",
    "normal_std_6 = np.sqrt(np.log(1 + (x6_std/x6_mean)**2))\n",
    "normal_mean_6 = np.log(x6_mean) - normal_std_6**2 / 2\n",
    "\n",
    "# X7 = theta_e (rad) mean=pi/4    cov=0.577 uniform / [0,pi/2]\n",
    "x7_min = 0\n",
    "x7_max = np.pi / 2\n",
    "\n",
    "# X8 = theta_p (rad) mean=pi/4    cov=0.577 uniform / [0,pi/2]\n",
    "x8_min = 0\n",
    "x8_max = np.pi / 2\n",
    "\n",
    "# X9 = phi_p (rad) mean=pi   cov=0.577 uniform / [0,pi*2]\n",
    "x9_min = 0\n",
    "x9_max = np.pi*2\n",
    "\n",
    "# X10 = f (MHz) mean=30    cov=0.096 uniform / [25 ,35]\n",
    "x10_min = 25e6\n",
    "x10_max = 35e6\n",
    "\n",
    "# X11 = alpha (-) mean=0.0010  cov=0.289 uniform / [0.0005 , 0.0015]\n",
    "x11_min = 0.0005\n",
    "x11_max =  0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a460188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.000218, 3.517276105428664)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 11\n",
    "n_mcs = int(1e6)\n",
    "X = np.zeros((n_mcs,dim))\n",
    "L = X[:,0] = np.random.lognormal(mean=normal_mean_1, sigma=normal_std_1, size=n_mcs)   #L (m)\n",
    "h = X[:,1] = np.random.lognormal(mean=normal_mean_2, sigma=normal_std_2, size=n_mcs)   #h (m)\n",
    "d = X[:,2] = np.random.lognormal(mean=normal_mean_3, sigma=normal_std_3, size=n_mcs)   #d (m)\n",
    "ZL = X[:,3] = np.random.lognormal(mean=normal_mean_4, sigma=normal_std_4, size=n_mcs)   #ZL ()\n",
    "Z0 = X[:,4] = np.random.lognormal(mean=normal_mean_5, sigma=normal_std_5, size=n_mcs)   #Z0 ()\n",
    "ae = X[:,5] = np.random.lognormal(mean=normal_mean_6, sigma=normal_std_6, size=n_mcs)   #ae (V/m)\n",
    "theta_e = X[:,6] = np.random.uniform(low=x7_min, high=x7_max, size=n_mcs)        #theta_e (rad)\n",
    "theta_p = X[:,7] = np.random.uniform(low=x8_min, high=x8_max, size=n_mcs)        #theta_p (rad)\n",
    "phi_p =  X[:,8] = np.random.uniform(low=x9_min, high=x9_max, size=n_mcs)        #phi_p (rad)\n",
    "f = X[:,9] = np.random.uniform(low=x10_min, high=x10_max, size=n_mcs)      #f (MHz)\n",
    "alpha = X[:,10] = np.random.uniform(low=x11_min, high=x11_max, size=n_mcs)     #alpha (-)\n",
    "\n",
    "y_test = function(X)\n",
    "y_max = np.max(y_test)\n",
    "Pf_ref = np.sum( y_test < 0 ) / n_mcs\n",
    "B_ref= - norm.ppf( Pf_ref )\n",
    "Pf_ref, B_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927a5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = {'x1': [x1_mean, x1_std, 'lognormal'],\n",
    " 'x2': [x2_mean, x2_std, 'lognormal'],\n",
    " 'x3': [x3_mean, x3_std, 'lognormal'],\n",
    " 'x4': [x4_mean, x4_std, 'lognormal'],\n",
    " 'x5': [x5_mean, x5_std, 'lognormal'],\n",
    " 'x6': [x6_mean, x6_std, 'lognormal'],\n",
    " 'x7': [x7_min, x7_max, 'uniform'],\n",
    " 'x8': [x8_min, x8_max, 'uniform'],\n",
    " 'x9': [x9_min, x9_max, 'uniform'],\n",
    " 'x10': [x10_min, x10_max, 'uniform'],\n",
    " 'x11': [x11_min, x11_max, 'uniform']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ea2bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:  1 ########################################################\n",
      "Training BNN With 50 samples\n",
      "Training completed\n",
      "Minimum loss:  13.645233154296875\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000242 PF = 0.012464 and B = 2.24300 -------------------------------\n",
      " \n",
      "Training BNN With 60 samples\n",
      "Training completed\n",
      "Minimum loss:  10.13916301727295\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000234 PF = 0.035724 and B = 1.80300 -------------------------------\n",
      " \n",
      "Training BNN With 70 samples\n",
      "Training completed\n",
      "Minimum loss:  8.864086151123047\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000247 PF = 0.020285 and B = 2.04800 -------------------------------\n",
      " \n",
      "Training BNN With 80 samples\n",
      "Training completed\n",
      "Minimum loss:  5.568042278289795\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000239 PF = 0.022759 and B = 2.00000 -------------------------------\n",
      " \n",
      "Training BNN With 90 samples\n",
      "Training completed\n",
      "Minimum loss:  4.987165451049805\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.00022 PF = 0.016082 and B = 2.14200 -------------------------------\n",
      " \n",
      "Training BNN With 100 samples\n",
      "Training completed\n",
      "Minimum loss:  3.9580016136169434\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000259 PF = 0.033074 and B = 1.83700 -------------------------------\n",
      " \n",
      "Training BNN With 110 samples\n",
      "Training completed\n",
      "Minimum loss:  -0.38856497406959534\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000253 PF = 0.047934 and B = 1.66500 -------------------------------\n",
      " \n",
      "Training BNN With 120 samples\n",
      "Training completed\n",
      "Minimum loss:  1.8151177167892456\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000228 PF = 0.024829 and B = 1.96300 -------------------------------\n",
      " \n",
      "Training BNN With 130 samples\n",
      "Training completed\n",
      "Minimum loss:  0.9713895916938782\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000217 PF = 0.00869 and B = 2.37900 -------------------------------\n",
      " \n",
      "Training BNN With 140 samples\n",
      "Training completed\n",
      "Minimum loss:  -1.553139328956604\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000225 PF = 0.011267 and B = 2.28100 -------------------------------\n",
      " \n",
      "Training BNN With 150 samples\n",
      "Training completed\n",
      "Minimum loss:  -2.5990607738494873\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.00022 PF = 0.00836 and B = 2.39300 -------------------------------\n",
      " \n",
      "Training BNN With 160 samples\n",
      "Training completed\n",
      "Minimum loss:  -0.2465021163225174\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000219 PF = 0.015417 and B = 2.15900 -------------------------------\n",
      " \n",
      "Training BNN With 170 samples\n",
      "Training completed\n",
      "Minimum loss:  -2.780900239944458\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000254 PF = 0.133708 and B = 1.10900 -------------------------------\n",
      " \n",
      "Training BNN With 180 samples\n",
      "Training completed\n",
      "Minimum loss:  -2.2897939682006836\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000225 PF = 0.017917 and B = 2.09900 -------------------------------\n",
      " \n",
      "Training BNN With 190 samples\n",
      "Training completed\n",
      "Minimum loss:  -0.8724309802055359\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000253 PF = 0.0329 and B = 1.84000 -------------------------------\n",
      " \n",
      "Training BNN With 200 samples\n",
      "Training completed\n",
      "Minimum loss:  -0.9447126984596252\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000242 PF = 0.005884 and B = 2.51900 -------------------------------\n",
      " \n",
      "Training BNN With 210 samples\n",
      "Training completed\n",
      "Minimum loss:  -2.848816156387329\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000221 PF = 0.997757 and B = -2.84200 -------------------------------\n",
      " \n",
      "Training BNN With 220 samples\n",
      "Training completed\n",
      "Minimum loss:  -2.7286031246185303\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000256 PF = 0.005363 and B = 2.55200 -------------------------------\n",
      " \n",
      "Training BNN With 230 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.75227427482605\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000232 PF = 0.985009 and B = -2.17000 -------------------------------\n",
      " \n",
      "Training BNN With 240 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.1895439624786377\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000228 PF = 0.018173 and B = 2.09300 -------------------------------\n",
      " \n",
      "Training BNN With 250 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.793428421020508\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000242 PF = 0.004264 and B = 2.63000 -------------------------------\n",
      " \n",
      "Training BNN With 260 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.3605144023895264\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000251 PF = 0.005157 and B = 2.56500 -------------------------------\n",
      " \n",
      "Training BNN With 270 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.585709571838379\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000209 PF = 0.133022 and B = 1.11200 -------------------------------\n",
      " \n",
      "Training BNN With 280 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.7211225032806396\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000263 PF = 0.980552 and B = -2.06500 -------------------------------\n",
      " \n",
      "Training BNN With 290 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.825151205062866\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000238 PF = 0.006136 and B = 2.50400 -------------------------------\n",
      " \n",
      "Training BNN With 300 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.2023441791534424\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000233 PF = 0.023697 and B = 1.98300 -------------------------------\n",
      " \n",
      "Training BNN With 310 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.7269444465637207\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000238 PF = 0.013656 and B = 2.20700 -------------------------------\n",
      " \n",
      "Training BNN With 320 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.337083339691162\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000257 PF = 0.009965 and B = 2.32800 -------------------------------\n",
      " \n",
      "Training BNN With 330 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.963688611984253\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000231 PF = 0.04688 and B = 1.67600 -------------------------------\n",
      " \n",
      "Training BNN With 340 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.000657081604004\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.00024 PF = 0.003327 and B = 2.71400 -------------------------------\n",
      " \n",
      "Training BNN With 350 samples\n",
      "Training completed\n",
      "Minimum loss:  -3.7778313159942627\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000223 PF = 0.967347 and B = -1.84300 -------------------------------\n",
      " \n",
      "Training BNN With 360 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.233368873596191\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000247 PF = 0.005255 and B = 2.55900 -------------------------------\n",
      " \n",
      "Training BNN With 370 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.192987442016602\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000248 PF = 0.007663 and B = 2.42500 -------------------------------\n",
      " \n",
      "Training BNN With 380 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.223400115966797\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000231 PF = 0.009337 and B = 2.35200 -------------------------------\n",
      " \n",
      "Training BNN With 390 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.813394069671631\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000233 PF = 0.072784 and B = 1.45500 -------------------------------\n",
      " \n",
      "Training BNN With 400 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.314709663391113\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000246 PF = 0.003499 and B = 2.69700 -------------------------------\n",
      " \n",
      "Training BNN With 410 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.770437717437744\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000225 PF = 0.933911 and B = -1.50600 -------------------------------\n",
      " \n",
      "Training BNN With 420 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.338668346405029\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000262 PF = 0.004943 and B = 2.58000 -------------------------------\n",
      " \n",
      "Training BNN With 430 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.607786178588867\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000221 PF = 0.019428 and B = 2.06600 -------------------------------\n",
      " \n",
      "Training BNN With 440 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.596327304840088\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000252 PF = 0.004058 and B = 2.64700 -------------------------------\n",
      " \n",
      "Training BNN With 450 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.561743259429932\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000256 PF = 0.001244 and B = 3.02500 -------------------------------\n",
      " \n",
      "Training BNN With 460 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.902434349060059\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000242 PF = 0.081738 and B = 1.39300 -------------------------------\n",
      " \n",
      "Training BNN With 470 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.697618007659912\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000216 PF = 0.992286 and B = -2.42200 -------------------------------\n",
      " \n",
      "Training BNN With 480 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.629037857055664\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000219 PF = 0.159998 and B = 0.99400 -------------------------------\n",
      " \n",
      "Training BNN With 490 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.286611557006836\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000251 PF = 0.998154 and B = -2.90300 -------------------------------\n",
      " \n",
      "Training BNN With 500 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.868382453918457\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000231 PF = 0.006525 and B = 2.48200 -------------------------------\n",
      " \n",
      "Training BNN With 510 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.863984107971191\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000264 PF = 0.001249 and B = 3.02400 -------------------------------\n",
      " \n",
      "Training BNN With 520 samples\n",
      "Training completed\n",
      "Minimum loss:  -5.027439117431641\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000245 PF = 0.989355 and B = -2.30300 -------------------------------\n",
      " \n",
      "Training BNN With 530 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.826327323913574\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000235 PF = 0.014345 and B = 2.18800 -------------------------------\n",
      " \n",
      "Training BNN With 540 samples\n",
      "Training completed\n",
      "Minimum loss:  -4.7963643074035645\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000239 PF = 0.003309 and B = 2.71500 -------------------------------\n",
      " \n",
      "Training BNN With 550 samples\n",
      "Training completed\n",
      "Minimum loss:  -5.105091571807861\n",
      "BNN predictions with MC population...\n",
      "PF_ref = 0.000263 PF = 0.007234 and B = 2.44500 -------------------------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "number_experiments = 1\n",
    "passive_samples = 50\n",
    "active_samples = 50\n",
    "output = 1\n",
    "layers, archit = 3 , [30, 30, 30]  #change archit size if layers are increased\n",
    "bnn_simulations = 100\n",
    "training_epochs = 5000\n",
    "n_mcs = int(1e6)\n",
    "learning_points = 10\n",
    "\n",
    "for experiments in range(number_experiments):\n",
    "    print('Experiment: ', experiments+1 , '########################################################' )\n",
    "    \n",
    "    ActiveTrain_1 = {}\n",
    "\n",
    "    #PASSIVE TRAINING---------------------------------------------------\n",
    "    X = np.zeros((passive_samples, dim))\n",
    "    X_norm = np.zeros((passive_samples, dim))\n",
    "   \n",
    "    exp_norm = {}\n",
    "    for var_name in range(dim):\n",
    "        exp_norm['x'+ str(var_name+1)] = [0.000001, 0.999999]    #initial design domain for each variable (normal, uniform)\n",
    "\n",
    "    #Latin hypercube sampling\n",
    "    Xdoe = build.space_filling_lhs(exp_norm , num_samples = passive_samples)\n",
    "\n",
    "    for margin in range (0, dim):\n",
    "        var = 'x' + str (margin + 1)\n",
    "        X_norm[:, margin] = Xdoe[var]\n",
    "\n",
    "        if exp[var][2] == 'normal':\n",
    "            loc_ = exp[var][0]\n",
    "            scale_ = exp[var][1]\n",
    "            X[:, margin] = norm.ppf(Xdoe[var], loc=loc_, scale=scale_)\n",
    "\n",
    "        elif exp[var][2] == 'uniform':\n",
    "            loc_ = exp[var][0]\n",
    "            scale_ = exp[var][1]\n",
    "            X[:, margin] = uniform.ppf(Xdoe[var], loc=loc_, scale=scale_-loc_)\n",
    "\n",
    "        elif exp[var][2] == 'lognormal':\n",
    "            xlog_mean = exp[var][0]\n",
    "            xlog_std = exp[var][1]\n",
    "            gaussian_param = convert_lognormal(xlog_mean, xlog_std)\n",
    "            X[:, margin] = lognorm.ppf(Xdoe[var], s=gaussian_param[1], scale=xlog_mean) \n",
    "\n",
    "    Y = function(X)\n",
    "\n",
    "    #ACTIVE TRAIN LOOP ---------------------------------------------------\n",
    "    for active in range(passive_samples, active_samples+passive_samples+1):\n",
    "        #-------------------------------------------creating bnn\n",
    "        #setting up the network architecture -----------------------------------\n",
    "        config = {\"n_infeatures\": dim,\n",
    "                \"n_outfeatures\": output,\n",
    "                \"n_samples\": len(X_norm),\n",
    "                \"learn_all_params\": False,  #to learn mean and sigma\n",
    "                \"fixed_param\": 0.001} \n",
    "        \n",
    "        ModelName = 'BNN_' + str(len(X_norm))\n",
    "        mybnn = Pbnn(config)\n",
    "        \n",
    "        mybnn.build_bnn(layers, archit) #----------------------------------------------------------MODEL ARCHITECTURE\n",
    "        #-------------------------------------------training bnn\n",
    "        \n",
    "        # batch_size = len(X)\n",
    "        batch_size = 8\n",
    "        # batch_size = [np.floor_divide(len(X), 10)][0] + 1  # splitting DoE\n",
    "\n",
    "        train_env = {\"batch_size\": batch_size,\n",
    "                    \"learning_rate\": 0.001,\n",
    "                    \"epochs\": training_epochs,\n",
    "                    \"callback_patience\": 500,\n",
    "                    \"verbose\": 0,\n",
    "                    \"valid_split\":0.0}\n",
    "        \n",
    "        print('Training BNN With', len(X_norm), 'samples' )\n",
    "        history = mybnn.train_bnn(X_norm, Y, train_env)\n",
    "\n",
    "        #-------------------------------------------MC population\n",
    "        Xtest = np.zeros((int(n_mcs), dim))\n",
    "        MCinputs_norm= np.random.uniform(0.000001, 0.999999, size=(int(n_mcs), dim))\n",
    "\n",
    "        for margin in range (0, dim):\n",
    "            var = 'x' + str (margin + 1)\n",
    "\n",
    "            if exp[var][2] == 'normal':\n",
    "                loc_ = exp[var][0]\n",
    "                scale_ = exp[var][1]\n",
    "                Xtest[:, margin] = norm.ppf(MCinputs_norm[:, margin], loc=loc_, scale=scale_)\n",
    "\n",
    "            elif exp[var][2] == 'uniform':\n",
    "                loc_ = exp[var][0]\n",
    "                scale_ = exp[var][1]\n",
    "                Xtest[:, margin] = uniform.ppf(MCinputs_norm[:, margin], loc=loc_, scale=scale_-loc_)\n",
    "\n",
    "            elif exp[var][2] == 'lognormal':\n",
    "                xlog_mean = exp[var][0]\n",
    "                xlog_std = exp[var][1]\n",
    "                gaussian_param = convert_lognormal(xlog_mean, xlog_std)\n",
    "                Xtest[:, margin] = lognorm.ppf(MCinputs_norm[:, margin], s=gaussian_param[1], scale=xlog_mean) \n",
    "\n",
    "        #-------------------------------------------model predictions over MC population\n",
    "        print('BNN predictions with MC population...')\n",
    "        Mean_muY_MC, Stdv_muY_MC, Mean_sigmaY_MC, Stdv_sigmaY_MC = mybnn.modeluq_bnn(MCinputs_norm, nsim = bnn_simulations)\n",
    "        y_mcs = function(Xtest)\n",
    "\n",
    "        PF = np.sum(Mean_muY_MC < 0) / n_mcs\n",
    "        B = - norm.ppf( PF )\n",
    "        PF_ref = np.sum(y_mcs < 0) / n_mcs\n",
    "\n",
    "        print('PF_ref =', PF_ref, 'PF =', PF, 'and B =',\"%.5f\" % round(B, 3) ,'-------------------------------')\n",
    "        print(' ')\n",
    "        #-------------------------------------------Selecting new training point\n",
    "        U_f = np.abs(Mean_muY_MC) / Stdv_muY_MC\n",
    "        U_min_args = np.argsort(U_f.reshape(-1))     #ordering arguments from min to max\n",
    "        X_new = Xtest[U_min_args[:learning_points]]  #choosing a given number of MC samples from the minimum U values\n",
    "        X_new_norm = MCinputs_norm[U_min_args[:learning_points]]  #choosing a given number of MC samples from the minimum U values\n",
    "        X_norm = np.concatenate((X_norm, X_new_norm), axis=0)\n",
    "\n",
    "        Y_new = function(X_new)\n",
    "        Y = np.concatenate((Y, Y_new), axis=0)\n",
    "\n",
    "        #-------------------------------------------Saving results\n",
    "        ActiveTrain_1[ModelName] = mybnn.weights, PF, B\n",
    "        filename1 = 'Batch_'+ str(experiments+1)+'.sav'\n",
    "    \n",
    "        pickle.dump(ActiveTrain_1, open(filename1, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4c11d",
   "metadata": {},
   "source": [
    "to sample with sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = qmc.Sobol(d=2, scramble=True)    #d=dimensionality\n",
    "sample = sampler.random_base2(m=5)   #change m=exponent to increase the sample size\n",
    "\n",
    "l_bounds = [-2.0, -2.0]  #design domain for each variable in the physical space\n",
    "u_bounds = [2.0, 2.0]\n",
    "X = qmc.scale(sample, l_bounds, u_bounds)\n",
    "\n",
    "Y = function(X)\n",
    "passive_samples = len(X)\n",
    "print(passive_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ded18",
   "metadata": {},
   "source": [
    "Select MULTIPLE NEW training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e80891",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_points = 5\n",
    "#-------------------------------------------Selecting MULTIPLE NEW training point\n",
    "# U_f = np.abs(Mean_muY_MC) / Stdv_muY_MC\n",
    "U_f = Stdv_muY_MC\n",
    "\n",
    "U_min_args = np.argsort(U_f.reshape(-1))     #ordering arguments from min to max\n",
    "X_new = Xtest[U_min_args[:learning_points]]  #choosing a given number of MC samples from the minimum U values\n",
    "X = np.concatenate((X, X_new), axis=0)\n",
    "\n",
    "Y_new = function(X_new)\n",
    "Y = np.concatenate((Y, Y_new), axis=0)\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3824806",
   "metadata": {},
   "source": [
    "Select SINGLE NEW Training point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5366154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------Selecting SINGLE NEW training point\n",
    "U_f = np.abs(Mean_muY_MC) / Stdv_muY_MC\n",
    "U_min = np.argmin(U_f)\n",
    "X_new = Xtest[U_min].reshape(-1, dim)\n",
    "# X = np.concatenate((X, X_new), axis=0)\n",
    "\n",
    "Y_new = function(X_new)\n",
    "# Y = np.concatenate((Y, Y_new), axis=0)\n",
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
