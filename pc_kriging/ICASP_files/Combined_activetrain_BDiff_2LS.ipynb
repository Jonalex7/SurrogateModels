{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209ad2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pc_kriging import PC_Kriging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from doepy import build\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import pickle\n",
    "\n",
    "from scipy.special import eval_legendre, eval_hermitenorm\n",
    "import scipy.special\n",
    "\n",
    "# adaptive learning - expected feasiability function --------------------------------------------------------------\n",
    "\n",
    "def EFF(u,v,z):\n",
    "    zl=-2*v\n",
    "    zh=2*v\n",
    "    return ((u-z)*( 2*norm.cdf((z-u)/v) - norm.cdf((zl-u)/v) - norm.cdf((zh-u)/v)) \n",
    "           -(v)*( 2*norm.pdf((z-u)/v) - norm.pdf((zl-u)/v) - norm.pdf((zh-u)/v))  \n",
    "           +(2*v)*(norm.cdf((zh-u)/v) - norm.cdf((zl-u)/v)))\n",
    "\n",
    "def U_function(u, v):\n",
    "    return np.abs(u)/v\n",
    "\n",
    "def LinearNorm(x,oldmin,oldmax,newmin,newmax):    # scaling linearly X to new domain limits\n",
    "    return newmin + ((x-oldmin)*(newmax-newmin)/(oldmax-oldmin))\n",
    "\n",
    "\n",
    "def VoronoiCell(x,xn):   #given x [single value] return the index of the closest xn [array]\n",
    "    dist=PCK1.distance(x.reshape(1,-1),xn)\n",
    "    return np.argmin(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b3960",
   "metadata": {},
   "source": [
    "# Limit State 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f746b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ground truth function 1 ----------------------------------------------------\n",
    "# https://rprepo.readthedocs.io/en/latest/reliability_problems.html#rp201\n",
    "\n",
    "def gfun_53(x):\n",
    "    \"\"\"Performance function for reliability problem 53.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        x : numpy.array of float(s)\n",
    "            Values of independent variables: columns are the different parameters/random variables (x1, x2,...xn) and rows are different parameter/random variables sets for different calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        g_val_sys : numpy.array of float(s)\n",
    "            Performance function value for the system.\n",
    "        g_val_comp : numpy.array of float(s)\n",
    "            Performance function value for each component.\n",
    "        msg : str\n",
    "            Accompanying diagnostic message, e.g. warning.\n",
    "    \"\"\"\n",
    "#     import numpy as np\n",
    "    # expected number of random variables/columns\n",
    "    nrv_e = 2\n",
    "\n",
    "    g = float('nan')\n",
    "    msg = 'Ok'\n",
    "    x = np.array(x, dtype='f')\n",
    "\n",
    "    n_dim = len(x.shape)\n",
    "    if n_dim == 1:\n",
    "        x = np.array(x)[np.newaxis]\n",
    "    elif n_dim > 2:\n",
    "        msg = 'Only available for 1D and 2D arrays.'\n",
    "        return float('nan'), float('nan'), msg\n",
    "\n",
    "    nrv_p = x.shape[1]\n",
    "    if nrv_p != nrv_e:\n",
    "        msg = f'The number of random variables (x, columns) is expected to be {nrv_e} but {nrv_p} is provided!'\n",
    "    else:\n",
    "        g = np.sin(5*x[:, 0]/2) + 2 - (x[:, 0]**2 + 4)*(x[:, 1] - 1)/20\n",
    "\n",
    "    g_val_sys = g\n",
    "    g_val_comp = g\n",
    "    return g_val_sys, g_val_comp, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f87351",
   "metadata": {},
   "source": [
    "# Limit State 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c1a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth function 2 ----------------------------------------------------\n",
    "# https://rprepo.readthedocs.io/en/latest/reliability_problems.html#rp201\n",
    "\n",
    "def LState2(x):\n",
    "    #\"\"\"Modified Performance function for reliability problem 53\"\"\"\"\n",
    "  \n",
    "    # expected number of random variables/columns\n",
    "    nrv_e = 2\n",
    "\n",
    "    g = float('nan')\n",
    "    msg = 'Ok'\n",
    "    x = np.array(x, dtype='f')\n",
    "\n",
    "    n_dim = len(x.shape)\n",
    "    if n_dim == 1:\n",
    "        x = np.array(x)[np.newaxis]\n",
    "    elif n_dim > 2:\n",
    "        msg = 'Only available for 1D and 2D arrays.'\n",
    "        return float('nan'), float('nan'), msg\n",
    "\n",
    "    nrv_p = x.shape[1]\n",
    "    if nrv_p != nrv_e:\n",
    "        msg = f'The number of random variables (x, columns) is expected to be {nrv_e} but {nrv_p} is provided!'\n",
    "    else:\n",
    "        g = np.sin(2.0*x[:, 0]) -0.5 - (x[:, 0]**2 + 4)*(-1.0*x[:, 1] - 1)/20\n",
    "\n",
    "    g_val_sys = g\n",
    "    g_val_comp = g\n",
    "    return g_val_sys, g_val_comp, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cda3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"pol_type\": ['hermite', 'hermite']}   #design variables following normal distribution\n",
    "PCK1 = PC_Kriging(config)\n",
    "PCK_loo = PC_Kriging(config)    # for LOOCV with same 'config' as specified in the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7f6e2",
   "metadata": {},
   "source": [
    "## Initial training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbcc9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_1 = gfun_53   #ground truth function 1 \n",
    "function_2 = LState2   #ground truth function 2\n",
    "\n",
    "dim = 2       # dimensionality\n",
    "\n",
    "x1mean, x1sigma = 1.5 , 1.0  # normal distribution \n",
    "x2mean, x2sigma = 2.5 , 1.0  # normal distribution \n",
    "\n",
    "ntest = 5000  # test points\n",
    "\n",
    "# TEST POINTS -------------------------------------------------\n",
    "XR = np.zeros((int(ntest), dim))   #normalized test points\n",
    "XN = np.zeros((int(ntest), dim))  #scaled test points\n",
    "YN_1 = np.zeros(int(ntest))\n",
    "YN_2 = np.zeros(int(ntest))\n",
    "#variable 1 ---------------------------------------------------\n",
    "XN[:,0] = np.random.normal(0,1,ntest)  \n",
    "XR[:,0] = PCK1.scalehermite(XN[:,0], x1mean, x1sigma)  \n",
    "#variable 2 ---------------------------------------------------\n",
    "XN[:,1] = np.random.normal(0,1,ntest)  \n",
    "XR[:,1] = PCK1.scalehermite(XN[:,1], x2mean, x2sigma)  \n",
    "\n",
    "YN_1 = function_1(XR)[0]\n",
    "YN_2 = function_2(XR)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fbd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function to optimize length scale --------------------------------------------------------\n",
    "def L_Object (l):\n",
    "    v = 5/2\n",
    "    N = len(xn)\n",
    "    R = PCK1.matern(xn , xn, l, v)\n",
    "    detR = np.linalg.det(R)\n",
    "    \n",
    "    modelpar2 = PCK1.train(xn, yn, p, np.array([l,v]))    # returns B, sig2, InfoMatrix(phi) , PolyIndices(alpha)\n",
    "    ### ------------------Theta_ by UQLab User Manual PCK(C. Lataniotis, D. Wicaksono, S. Marelli, B. Sudret)------------------------------\n",
    "    sig2 = modelpar2[1].reshape(-1)\n",
    "    # return 0.5*(np.log(detR)+ N*np.log(2*np.pi*sig2)+ N)\n",
    "\n",
    "    ### ------------------Theta_ by MLE PCK(Schobi,Sudret,Wiart)------------------------------\n",
    "    FB = PCK1.InfoMat @ modelpar2[0]\n",
    "    ins = (yn-FB).reshape(-1)\n",
    "    R_1 = np.linalg.inv(R)\n",
    "    return ((ins.T) @ R_1 @ ins) * (1/N) * (detR**(1/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd06881",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_samples_1 = np.sum(YN_1 < 0 )\n",
    "Pf_ref_1 = fail_samples_1/ntest\n",
    "\n",
    "fail_samples_2 = np.sum(YN_2 < 0 )\n",
    "Pf_ref_2 = fail_samples_2/ntest\n",
    "\n",
    "Pf_ref_1, Pf_ref_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(XR[:,0],XR[:,1], YN_1)\n",
    "ax.scatter(XR[:,0],XR[:,1], YN_2)             #plotting the last trained surrogate\n",
    "# ax.scatter(xr[:,0],xr[:,1], yn, color='red')   #observation points \n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('G_System')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b90e06",
   "metadata": {},
   "source": [
    "# Combined Active training - U - 2 LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d824e273",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:  1 #################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\surrogate\\lib\\site-packages\\ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS1:  Degree 1 e_LOO 3.340579728099612e-05 Pf_ref 0.03133 Pf 0.09373 CoV 0.00980\n",
      "LS2:  Degree 1 e_LOO 3.40098320395822e-05 Pf_ref 0.14797 Pf 0.16023 CoV 0.00720\n",
      "number of training points:  11 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0009989146416013739 Pf_ref 0.03087 Pf 0.00051 CoV 0.14000\n",
      "LS2:  Degree 3 e_LOO 1.6682120877382963e-05 Pf_ref 0.14772 Pf 0.24417 CoV 0.00560\n",
      "number of training points:  12 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0029915507935448843 Pf_ref 0.03205 Pf 0.00307 CoV 0.05700\n",
      "LS2:  Degree 1 e_LOO 0.0012277343579716062 Pf_ref 0.14693 Pf 0.04515 CoV 0.01450\n",
      "number of training points:  13 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0022569511932779298 Pf_ref 0.03164 Pf 0.00181 CoV 0.07430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\surrogate\\lib\\site-packages\\scipy\\optimize\\optimize.py:283: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  \"minimize step, clipping to bounds\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS2:  Degree 1 e_LOO 0.004263836094249737 Pf_ref 0.14831 Pf 0.05909 CoV 0.01260\n",
      "number of training points:  14 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.12702650499360166 Pf_ref 0.03171 Pf 0.02553 CoV 0.01950\n",
      "LS2:  Degree 1 e_LOO 0.025799101061218944 Pf_ref 0.15045 Pf 0.03163 CoV 0.01750\n",
      "number of training points:  15 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.05016007045232731 Pf_ref 0.03198 Pf 0.02224 CoV 0.02100\n",
      "LS2:  Degree 1 e_LOO 0.015813733296221304 Pf_ref 0.14798 Pf 0.02231 CoV 0.02090\n",
      "number of training points:  16 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.03701430062764798 Pf_ref 0.03007 Pf 0.05514 CoV 0.01310\n",
      "LS2:  Degree 2 e_LOO 0.021798308039560153 Pf_ref 0.14795 Pf 0.08492 CoV 0.01040\n",
      "number of training points:  17 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.07615057314229721 Pf_ref 0.03203 Pf 0.05348 CoV 0.01330\n",
      "LS2:  Degree 2 e_LOO 0.00022394368125544037 Pf_ref 0.14901 Pf 0.08593 CoV 0.01030\n",
      "number of training points:  18 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.08386538212489102 Pf_ref 0.03277 Pf 0.05357 CoV 0.01330\n",
      "LS2:  Degree 2 e_LOO 0.012998618437589234 Pf_ref 0.14674 Pf 0.09699 CoV 0.00960\n",
      "number of training points:  19 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0602046057388031 Pf_ref 0.03107 Pf 0.04872 CoV 0.01400\n",
      "LS2:  Degree 3 e_LOO 0.009702759160830543 Pf_ref 0.14863 Pf 0.05573 CoV 0.01300\n",
      "number of training points:  20 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.01037342132485558 Pf_ref 0.0322 Pf 0.03 CoV 0.01800\n",
      "LS2:  Degree 3 e_LOO 0.0024867387733589438 Pf_ref 0.14723 Pf 0.04875 CoV 0.01400\n",
      "number of training points:  21 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0365509636363634 Pf_ref 0.03155 Pf 0.01206 CoV 0.02860\n",
      "LS2:  Degree 3 e_LOO 0.0025228217763665008 Pf_ref 0.14576 Pf 0.05634 CoV 0.01290\n",
      "number of training points:  22 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.02436680951475558 Pf_ref 0.03163 Pf 0.01127 CoV 0.02960\n",
      "LS2:  Degree 3 e_LOO 1.4808041257749954e-06 Pf_ref 0.1488 Pf 0.03443 CoV 0.01670\n",
      "number of training points:  23 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.017987228314271377 Pf_ref 0.03151 Pf 0.01253 CoV 0.02810\n",
      "LS2:  Degree 3 e_LOO 0.008997355838804833 Pf_ref 0.14895 Pf 0.04891 CoV 0.01390\n",
      "number of training points:  24 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.031493434106137336 Pf_ref 0.03171 Pf 0.00342 CoV 0.05400\n",
      "LS2:  Degree 3 e_LOO 0.028743854442943206 Pf_ref 0.14852 Pf 0.05249 CoV 0.01340\n",
      "number of training points:  25 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.006374880098831867 Pf_ref 0.03088 Pf 0.00316 CoV 0.05620\n",
      "LS2:  Degree 3 e_LOO 0.009326854730789685 Pf_ref 0.14618 Pf 0.0443 CoV 0.01470\n",
      "number of training points:  26 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0034634136421079274 Pf_ref 0.03074 Pf 0.00324 CoV 0.05550\n",
      "LS2:  Degree 3 e_LOO 0.007299589530716597 Pf_ref 0.14846 Pf 0.04404 CoV 0.01470\n",
      "number of training points:  27 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0018103511826374839 Pf_ref 0.03132 Pf 0.00397 CoV 0.05010\n",
      "LS2:  Degree 3 e_LOO 0.0037991103078583175 Pf_ref 0.14773 Pf 0.04624 CoV 0.01440\n",
      "number of training points:  28 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0016342949226842186 Pf_ref 0.03133 Pf 0.00437 CoV 0.04770\n",
      "LS2:  Degree 3 e_LOO 0.004999738535110565 Pf_ref 0.14862 Pf 0.04494 CoV 0.01460\n",
      "number of training points:  29 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0005652992892801259 Pf_ref 0.03028 Pf 0.00412 CoV 0.04920\n",
      "LS2:  Degree 3 e_LOO 0.005429553669597907 Pf_ref 0.14913 Pf 0.03879 CoV 0.01570\n",
      "number of training points:  30 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0004985527035570441 Pf_ref 0.03141 Pf 0.00393 CoV 0.05030\n",
      "LS2:  Degree 3 e_LOO 0.00332933546378733 Pf_ref 0.14755 Pf 0.05694 CoV 0.01290\n",
      "number of training points:  31 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00025124781871245017 Pf_ref 0.03102 Pf 0.00328 CoV 0.05510\n",
      "LS2:  Degree 3 e_LOO 0.002209524198668707 Pf_ref 0.14797 Pf 0.06938 CoV 0.01160\n",
      "number of training points:  32 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.001058457744495132 Pf_ref 0.03211 Pf 0.00476 CoV 0.04570\n",
      "LS2:  Degree 3 e_LOO 0.003975356468805401 Pf_ref 0.14738 Pf 0.07026 CoV 0.01150\n",
      "number of training points:  33 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.001405464220513792 Pf_ref 0.03142 Pf 0.00416 CoV 0.04890\n",
      "LS2:  Degree 3 e_LOO 0.004727290200978983 Pf_ref 0.1489 Pf 0.08851 CoV 0.01010\n",
      "number of training points:  34 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0015800944876023415 Pf_ref 0.03152 Pf 0.00464 CoV 0.04630\n",
      "LS2:  Degree 3 e_LOO 0.00588307005562483 Pf_ref 0.14715 Pf 0.09448 CoV 0.00980\n",
      "number of training points:  35 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0013256896868077165 Pf_ref 0.03113 Pf 0.00483 CoV 0.04540\n",
      "LS2:  Degree 3 e_LOO 0.004473734150654549 Pf_ref 0.14707 Pf 0.09876 CoV 0.00960\n",
      "number of training points:  36 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00134551754157552 Pf_ref 0.03119 Pf 0.005 CoV 0.04460\n",
      "LS2:  Degree 3 e_LOO 0.004777425123676169 Pf_ref 0.1471 Pf 0.10084 CoV 0.00940\n",
      "number of training points:  37 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0008945344241915286 Pf_ref 0.02995 Pf 0.00539 CoV 0.04300\n",
      "LS2:  Degree 3 e_LOO 0.004197048727847959 Pf_ref 0.14995 Pf 0.10587 CoV 0.00920\n",
      "number of training points:  38 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0009116089460514756 Pf_ref 0.03133 Pf 0.0049 CoV 0.04510\n",
      "LS2:  Degree 3 e_LOO 0.0038530458827521078 Pf_ref 0.15093 Pf 0.11023 CoV 0.00900\n",
      "number of training points:  39 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0010591994461708746 Pf_ref 0.03165 Pf 0.00467 CoV 0.04620\n",
      "LS2:  Degree 3 e_LOO 0.003337267890819481 Pf_ref 0.14858 Pf 0.10785 CoV 0.00910\n",
      "number of training points:  40 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0009704650318098407 Pf_ref 0.03068 Pf 0.00504 CoV 0.04440\n",
      "LS2:  Degree 3 e_LOO 0.003203918480104335 Pf_ref 0.14971 Pf 0.10892 CoV 0.00900\n",
      "number of training points:  41 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0006579478800367579 Pf_ref 0.0317 Pf 0.00517 CoV 0.04390\n",
      "LS2:  Degree 3 e_LOO 0.0025315322471033126 Pf_ref 0.14854 Pf 0.11083 CoV 0.00900\n",
      "number of training points:  42 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0003047012481659401 Pf_ref 0.03137 Pf 0.00577 CoV 0.04150\n",
      "LS2:  Degree 3 e_LOO 0.0026762437976960924 Pf_ref 0.14818 Pf 0.11203 CoV 0.00890\n",
      "number of training points:  43 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.000123696872577868 Pf_ref 0.03145 Pf 0.00612 CoV 0.04030\n",
      "LS2:  Degree 3 e_LOO 0.0019437511897162313 Pf_ref 0.14835 Pf 0.12187 CoV 0.00850\n",
      "number of training points:  44 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0002942343522043217 Pf_ref 0.03138 Pf 0.0068 CoV 0.03820\n",
      "LS2:  Degree 3 e_LOO 0.002045442778253229 Pf_ref 0.1488 Pf 0.07623 CoV 0.01100\n",
      "number of training points:  45 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0009092598031075504 Pf_ref 0.03084 Pf 0.01004 CoV 0.03140\n",
      "LS2:  Degree 3 e_LOO 0.0015750106426071753 Pf_ref 0.1476 Pf 0.07705 CoV 0.01090\n",
      "number of training points:  46 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0011008822191737346 Pf_ref 0.03224 Pf 0.03808 CoV 0.01590\n",
      "LS2:  Degree 2 e_LOO 0.0014382265771125699 Pf_ref 0.14828 Pf 0.08566 CoV 0.01030\n",
      "number of training points:  47 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 0.00010634866394388912 Pf_ref 0.03086 Pf 0.02647 CoV 0.01920\n",
      "LS2:  Degree 3 e_LOO 0.001177328268787214 Pf_ref 0.14854 Pf 0.11436 CoV 0.00880\n",
      "number of training points:  48 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 0.0003427225697761849 Pf_ref 0.03207 Pf 0.02689 CoV 0.01900\n",
      "LS2:  Degree 3 e_LOO 0.001193236819334119 Pf_ref 0.14804 Pf 0.11621 CoV 0.00870\n",
      "number of training points:  49 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 0.0004387473581689378 Pf_ref 0.03057 Pf 0.02723 CoV 0.01890\n",
      "LS2:  Degree 3 e_LOO 0.0009079920148877263 Pf_ref 0.14834 Pf 0.11802 CoV 0.00860\n",
      "number of training points:  50 -------------------------------------------------\n",
      "Experiment:  2 #################################################################\n",
      "LS1:  Degree 1 e_LOO 1.9233478885068136e-05 Pf_ref 0.03157 Pf 0.08067 CoV 0.01070\n",
      "LS2:  Degree 1 e_LOO 2.2570770828419048e-05 Pf_ref 0.14797 Pf 0.14019 CoV 0.00780\n",
      "number of training points:  11 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0003647175251784515 Pf_ref 0.03028 Pf 0.00132 CoV 0.08700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\surrogate\\lib\\site-packages\\ipykernel_launcher.py:222: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS2:  Degree 2 e_LOO 0.000835533445912599 Pf_ref 0.14867 Pf 0.0 CoV inf\n",
      "number of training points:  12 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0006089686133179167 Pf_ref 0.03123 Pf 0.00349 CoV 0.05340\n",
      "LS2:  Degree 2 e_LOO 0.00033794443230606867 Pf_ref 0.15095 Pf 0.0 CoV inf\n",
      "number of training points:  13 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0013220726327578046 Pf_ref 0.0315 Pf 0.00411 CoV 0.04920\n",
      "LS2:  Degree 1 e_LOO 0.00029506368521980226 Pf_ref 0.1469 Pf 0.01534 CoV 0.02530\n",
      "number of training points:  14 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 3.420602017517905e-05 Pf_ref 0.03166 Pf 0.00237 CoV 0.06490\n",
      "LS2:  Degree 2 e_LOO 0.007881049250143324 Pf_ref 0.15146 Pf 0.00056 CoV 0.13360\n",
      "number of training points:  15 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0016085816844668523 Pf_ref 0.03102 Pf 0.00101 CoV 0.09950\n",
      "LS2:  Degree 2 e_LOO 0.0011580332874248037 Pf_ref 0.14884 Pf 2e-05 CoV 0.70710\n",
      "number of training points:  16 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0026743654674379847 Pf_ref 0.03121 Pf 0.00108 CoV 0.09620\n",
      "LS2:  Degree 1 e_LOO 0.00015409799405803116 Pf_ref 0.14761 Pf 0.02159 CoV 0.02130\n",
      "number of training points:  17 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0008706023443696682 Pf_ref 0.03131 Pf 0.00036 CoV 0.16660\n",
      "LS2:  Degree 2 e_LOO 5.325999311334023e-05 Pf_ref 0.15129 Pf 0.00076 CoV 0.11470\n",
      "number of training points:  18 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.010937193046926828 Pf_ref 0.03096 Pf 0.00087 CoV 0.10720\n",
      "LS2:  Degree 2 e_LOO 0.003405123170940811 Pf_ref 0.14991 Pf 0.0137 CoV 0.02680\n",
      "number of training points:  19 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0015127333573364777 Pf_ref 0.0319 Pf 9e-05 CoV 0.33330\n",
      "LS2:  Degree 2 e_LOO 0.0016224729567384851 Pf_ref 0.14799 Pf 0.02144 CoV 0.02140\n",
      "number of training points:  20 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0005182750494967296 Pf_ref 0.03147 Pf 0.00092 CoV 0.10420\n",
      "LS2:  Degree 2 e_LOO 0.0003758012581476488 Pf_ref 0.1492 Pf 0.06265 CoV 0.01220\n",
      "number of training points:  21 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 6.642924842317763e-05 Pf_ref 0.03128 Pf 0.00084 CoV 0.10910\n",
      "LS2:  Degree 2 e_LOO 0.000776735130449421 Pf_ref 0.14974 Pf 0.11 CoV 0.00900\n",
      "number of training points:  22 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00048102495415413475 Pf_ref 0.03214 Pf 0.00067 CoV 0.12210\n",
      "LS2:  Degree 2 e_LOO 0.0014742389006443832 Pf_ref 0.1491 Pf 0.11329 CoV 0.00880\n",
      "number of training points:  23 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0006697140136698283 Pf_ref 0.03179 Pf 0.00011 CoV 0.30150\n",
      "LS2:  Degree 2 e_LOO 0.00029886553286080246 Pf_ref 0.14901 Pf 0.11303 CoV 0.00890\n",
      "number of training points:  24 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 8.536426333838888e-08 Pf_ref 0.03181 Pf 0.00057 CoV 0.13240\n",
      "LS2:  Degree 2 e_LOO 0.00034461622055022474 Pf_ref 0.14644 Pf 0.10869 CoV 0.00910\n",
      "number of training points:  25 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 4.137904741356778e-06 Pf_ref 0.0312 Pf 0.00058 CoV 0.13130\n",
      "LS2:  Degree 2 e_LOO 0.0003572807641082508 Pf_ref 0.14843 Pf 0.11384 CoV 0.00880\n",
      "number of training points:  26 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 9.544088289104893e-08 Pf_ref 0.03209 Pf 0.00067 CoV 0.12210\n",
      "LS2:  Degree 2 e_LOO 0.0012069359736210142 Pf_ref 0.14929 Pf 0.11516 CoV 0.00880\n",
      "number of training points:  27 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 1.4145788608232704e-05 Pf_ref 0.03159 Pf 0.00048 CoV 0.14430\n",
      "LS2:  Degree 2 e_LOO 0.0003699253557162691 Pf_ref 0.14857 Pf 0.11622 CoV 0.00870\n",
      "number of training points:  28 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 1.4181396988557255e-05 Pf_ref 0.03197 Pf 0.00063 CoV 0.12590\n",
      "LS2:  Degree 2 e_LOO 0.001043223574159438 Pf_ref 0.14773 Pf 0.14085 CoV 0.00780\n",
      "number of training points:  29 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 6.378684008286127e-05 Pf_ref 0.03051 Pf 0.00053 CoV 0.13730\n",
      "LS2:  Degree 2 e_LOO 8.087303909573917e-06 Pf_ref 0.14905 Pf 0.14328 CoV 0.00770\n",
      "number of training points:  30 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 1.3380892167517346e-05 Pf_ref 0.03176 Pf 6e-05 CoV 0.40820\n",
      "LS2:  Degree 2 e_LOO 6.324679970495243e-05 Pf_ref 0.14869 Pf 0.14297 CoV 0.00770\n",
      "number of training points:  31 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 1.485395622214005e-06 Pf_ref 0.03119 Pf 7e-05 CoV 0.37800\n",
      "LS2:  Degree 2 e_LOO 2.238708991058793e-05 Pf_ref 0.14652 Pf 0.13723 CoV 0.00790\n",
      "number of training points:  32 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 2.3518173009112198e-05 Pf_ref 0.0321 Pf 7e-05 CoV 0.37800\n",
      "LS2:  Degree 2 e_LOO 1.2763046847121432e-05 Pf_ref 0.14703 Pf 0.14115 CoV 0.00780\n",
      "number of training points:  33 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0001393887189482229 Pf_ref 0.0306 Pf 7e-05 CoV 0.37800\n",
      "LS2:  Degree 2 e_LOO 5.5178080439865786e-05 Pf_ref 0.14799 Pf 0.14253 CoV 0.00780\n",
      "number of training points:  34 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 6.695047280874477e-05 Pf_ref 0.03103 Pf 8e-05 CoV 0.35350\n",
      "LS2:  Degree 2 e_LOO 3.306728639738333e-07 Pf_ref 0.14891 Pf 0.14472 CoV 0.00770\n",
      "number of training points:  35 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0001602822395486878 Pf_ref 0.03182 Pf 9e-05 CoV 0.33330\n",
      "LS2:  Degree 2 e_LOO 5.211792524953485e-06 Pf_ref 0.14918 Pf 0.14629 CoV 0.00760\n",
      "number of training points:  36 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.00012770737456251188 Pf_ref 0.03142 Pf 9e-05 CoV 0.33330\n",
      "LS2:  Degree 2 e_LOO 3.1988481594556975e-07 Pf_ref 0.14848 Pf 0.14616 CoV 0.00760\n",
      "number of training points:  37 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.00012208486981066293 Pf_ref 0.03218 Pf 0.00011 CoV 0.30150\n",
      "LS2:  Degree 2 e_LOO 1.446836372296709e-05 Pf_ref 0.14908 Pf 0.14866 CoV 0.00760\n",
      "number of training points:  38 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 9.877834214061176e-05 Pf_ref 0.03157 Pf 0.00012 CoV 0.28870\n",
      "LS2:  Degree 2 e_LOO 5.720233202219886e-05 Pf_ref 0.1481 Pf 0.14612 CoV 0.00760\n",
      "number of training points:  39 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0008149589050678274 Pf_ref 0.03073 Pf 0.00945 CoV 0.03240\n",
      "LS2:  Degree 2 e_LOO 0.00011229487245251035 Pf_ref 0.14738 Pf 0.15063 CoV 0.00750\n",
      "number of training points:  40 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00010061497935495203 Pf_ref 0.03119 Pf 0.00798 CoV 0.03530\n",
      "LS2:  Degree 2 e_LOO 0.00025025387340438335 Pf_ref 0.14881 Pf 0.14639 CoV 0.00760\n",
      "number of training points:  41 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 9.297190512388951e-05 Pf_ref 0.03088 Pf 0.01764 CoV 0.02360\n",
      "LS2:  Degree 2 e_LOO 2.8321136073374813e-05 Pf_ref 0.14807 Pf 0.14572 CoV 0.00770\n",
      "number of training points:  42 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 8.697597701056942e-06 Pf_ref 0.03116 Pf 0.01163 CoV 0.02920\n",
      "LS2:  Degree 2 e_LOO 5.147207882656738e-06 Pf_ref 0.1469 Pf 0.14511 CoV 0.00770\n",
      "number of training points:  43 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 7.346704842012306e-07 Pf_ref 0.0306 Pf 0.02223 CoV 0.02100\n",
      "LS2:  Degree 3 e_LOO 0.00042175911184551664 Pf_ref 0.14894 Pf 0.13863 CoV 0.00790\n",
      "number of training points:  44 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00017438824039458126 Pf_ref 0.03086 Pf 0.02103 CoV 0.02160\n",
      "LS2:  Degree 3 e_LOO 0.0004288731926634 Pf_ref 0.14788 Pf 0.13561 CoV 0.00800\n",
      "number of training points:  45 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.000573580836853549 Pf_ref 0.03071 Pf 0.02051 CoV 0.02190\n",
      "LS2:  Degree 3 e_LOO 0.0006192271445794711 Pf_ref 0.14769 Pf 0.13509 CoV 0.00800\n",
      "number of training points:  46 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00043073420046243864 Pf_ref 0.03073 Pf 0.02082 CoV 0.02170\n",
      "LS2:  Degree 3 e_LOO 0.0006648644277280489 Pf_ref 0.14804 Pf 0.14496 CoV 0.00770\n",
      "number of training points:  47 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.000529087918854761 Pf_ref 0.03105 Pf 0.02051 CoV 0.02190\n",
      "LS2:  Degree 3 e_LOO 0.0008709523144513378 Pf_ref 0.14898 Pf 0.1467 CoV 0.00760\n",
      "number of training points:  48 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0005361033567828806 Pf_ref 0.0325 Pf 0.02173 CoV 0.02120\n",
      "LS2:  Degree 3 e_LOO 0.0002037062526657783 Pf_ref 0.14756 Pf 0.14196 CoV 0.00780\n",
      "number of training points:  49 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0006825834319753938 Pf_ref 0.03133 Pf 0.02136 CoV 0.02140\n",
      "LS2:  Degree 3 e_LOO 0.00021319687300778458 Pf_ref 0.14663 Pf 0.14266 CoV 0.00780\n",
      "number of training points:  50 -------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "number_experiments = 15    \n",
    "number_active_points = 40\n",
    "\n",
    "results_file = '_CATBDiff_U_' + str(number_active_points)   # index for results files\n",
    "\n",
    "for experiments in range(number_experiments):\n",
    "    print('Experiment: ', experiments+1 , '#################################################################' )\n",
    "    \n",
    "    ActiveTrain_1 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "    ActiveTrain_2 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "\n",
    "    #INITIAL design of experiments (LHS) passive training ####################################\n",
    "\n",
    "    n = 10       # number of initial sampling\n",
    "\n",
    "    xn = np.zeros((int(n), dim))      #normalized training points\n",
    "    xr = np.zeros((int(n), dim))      #scaled training points\n",
    "    yn = np.zeros((int(n)))           #observations\n",
    "\n",
    "    # Check the variables limits for space-filling distribution\n",
    "    Xdoe = build.space_filling_lhs( {'x1':[-1, 1],      \n",
    "                                     'x2':[-1, 1],} , \n",
    "                                      num_samples = n )\n",
    "    #------------------------------------------------------------\n",
    "    xn[:,0] = Xdoe['x1']\n",
    "    xn[:,1] = Xdoe['x2']\n",
    "    xr[:,0] = PCK1.scalehermite(xn[:,0], x1mean, x1sigma)\n",
    "    xr[:,1] = PCK1.scalehermite(xn[:,1], x2mean, x2sigma)\n",
    "\n",
    "    yn_1 = function_1(xr)[0]\n",
    "    yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    # kernel hyperparameters-------------------------------------\n",
    "    v = 5/2        #Gaussian process\n",
    "    #truncation term-------------------------------------\n",
    "    p_max = 5  #for each variable â†’ same truncation , degree of expansion\n",
    "    \n",
    "    for points in range(number_active_points):\n",
    "\n",
    "        # Selecting the smallest e_loo model (length and order)\n",
    "        \n",
    "        mse_results = np.zeros(p_max-1)\n",
    "        opt_length_it = np.zeros(p_max-1)\n",
    "        eloo_results = np.zeros(p_max-1)\n",
    "\n",
    "        mean_loo = np.zeros(len(xn))\n",
    "        var_loo = np.zeros(len(xn))\n",
    "\n",
    "        dist = PCK1.distance(xn, xn)\n",
    "        lmax = np.max(dist)\n",
    "        lmin = np.min(dist[dist!=0])\n",
    "        bounds = [(lmin, lmax)]\n",
    "\n",
    "        results = dict()\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 1 #############################################\n",
    "    \n",
    "#         print('AT Limit state 1 ')\n",
    "\n",
    "        ModelName_1 = 'PCK1_' + str(len(xn))\n",
    "        \n",
    "        ModelName_1 = PC_Kriging(config)\n",
    "\n",
    "        # yn is changing for each LS (inside L_Object )\n",
    "        yn = yn_1    #observations\n",
    "        YN = YN_1    #test points\n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "\n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "\n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar1 = ModelName_1.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_1.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)    #selected based 'eloo' instead 'mse'\n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar1 = ModelName_1.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        ## Pool of samples for MCS -----------------------------------\n",
    "        MCS_samples = 100000\n",
    "\n",
    "        MCinputs_norm = np.zeros((int(MCS_samples), dim))\n",
    "        MCinputs = np.zeros((int(MCS_samples), dim))\n",
    "\n",
    "        MCinputs_norm[:,0] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "        MCinputs_norm[:,1] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "\n",
    "        MCinputs[:,0] = PCK1.scalehermite(MCinputs_norm[:,0], x1mean, x1sigma)  \n",
    "        MCinputs[:,1] = PCK1.scalehermite(MCinputs_norm[:,1], x2mean, x2sigma)  \n",
    "    \n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_1 = function_1(MCinputs)[0]  \n",
    "        fail_samples_1 = np.sum(ymc_1 < 0 )\n",
    "        Pf_ref_1 = fail_samples_1 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_1, varMC_1 = ModelName_1.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_1 = np.sum(np.asarray(meanMC_1) < 0 )\n",
    "        fail_prob_SUMO_1 = fail_samples_SUMO_1 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_1 ) / (fail_prob_SUMO_1 * MCS_samples) )\n",
    "\n",
    "        print('LS1: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results), 'Pf_ref', Pf_ref_1 ,'Pf', fail_prob_SUMO_1 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_1[str(len(xn))+'points'] = ModelName_1 , fail_prob_SUMO_1 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 2 #############################################\n",
    "        \n",
    "#         print('Training Limit state 2 ')\n",
    "        \n",
    "        ModelName_2 = 'PCK2_' + str(len(xn))\n",
    "        \n",
    "        ModelName_2 = PC_Kriging(config)\n",
    "        \n",
    "        # yn is changing for each LS \n",
    "        yn = yn_2\n",
    "        YN = YN_2\n",
    "        # Selecting the smallest e_loo model (length and order) \n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "            \n",
    "            # results = dict()\n",
    "            # bounds = [(lmin, lmax)]\n",
    "            \n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "\n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar2 = ModelName_2.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_2.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)    \n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar2 = ModelName_2.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_2 = function_2(MCinputs)[0]  \n",
    "        fail_samples_2 = np.sum(ymc_2 < 0 )\n",
    "        Pf_ref_2 = fail_samples_2 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_2, varMC_2 = ModelName_2.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_2 = np.sum(np.asarray(meanMC_2) < 0 )\n",
    "        fail_prob_SUMO_2 = fail_samples_SUMO_2 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_2 ) / (fail_prob_SUMO_2 * MCS_samples) )        \n",
    "        \n",
    "        print('LS2: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results) , 'Pf_ref', Pf_ref_2 ,'Pf', fail_prob_SUMO_2 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_2[str(len(xn))+'points'] = ModelName_2 , fail_prob_SUMO_2 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "\n",
    "        # ##############################################################################\n",
    "                   \n",
    "        if ( points == 0 ):   \n",
    "            meanMC = meanMC_1\n",
    "            varMC = varMC_1               \n",
    "            print ('LS 1')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        elif ( fail_prob_SUMO_1 == 0 ): \n",
    "            meanMC = meanMC_1\n",
    "            varMC = varMC_1              \n",
    "            print ('LS 1')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        elif ( fail_prob_SUMO_2 == 0 ): \n",
    "            meanMC = meanMC_2\n",
    "            varMC = varMC_2                \n",
    "            print ('LS 2')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        else:\n",
    "            Pf1_new = fail_prob_SUMO_1\n",
    "            Pf2_new = fail_prob_SUMO_2\n",
    "\n",
    "            B1_old = - norm.ppf ( Pf1_old )\n",
    "            B2_old = - norm.ppf ( Pf2_old )\n",
    "\n",
    "            B1_new = - norm.ppf ( Pf1_new )\n",
    "            B2_new = - norm.ppf ( Pf2_new )\n",
    "\n",
    "            B_error1 = abs(B1_old - B1_new ) / B1_old\n",
    "            B_error2 = abs(B2_old - B2_new ) / B2_old\n",
    "\n",
    "            if (B_error1 > B_error2):\n",
    "\n",
    "                meanMC = meanMC_1\n",
    "                varMC = varMC_1               \n",
    "                print (B_error1, B_error2, 'LS 1')\n",
    "\n",
    "                Pf1_old = fail_prob_SUMO_1\n",
    "                Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "            else:\n",
    "\n",
    "                meanMC = meanMC_2\n",
    "                varMC = varMC_2               \n",
    "                print (B_error1, B_error2, 'LS 2')\n",
    "\n",
    "                Pf1_old = fail_prob_SUMO_1\n",
    "                Pf2_old = fail_prob_SUMO_2\n",
    "                \n",
    "\n",
    "        ### Evaluating new points\n",
    "        U_f = U_function(meanMC.reshape(-1), varMC.reshape(-1))\n",
    "        \n",
    "        xr = np.append(xr, MCinputs[np.argmin(U_f)]).reshape(-1,2)\n",
    "        xn = np.append(xn, MCinputs_norm[np.argmin(U_f)]).reshape(-1,2)\n",
    "        \n",
    "        yn_1 = function_1(xr)[0]\n",
    "        yn_2 = function_2(xr)[0]\n",
    "    \n",
    "        print('number of training points: ', len(xn),'-------------------------------------------------')\n",
    "    filename1 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS1.sav'\n",
    "\n",
    "    pickle.dump(ActiveTrain_1, open(filename1, 'wb'))\n",
    "    \n",
    "    filename2 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS2.sav'\n",
    "    pickle.dump(ActiveTrain_2, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96fd7c",
   "metadata": {},
   "source": [
    "# Combined training - EFF - 2 LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0444d08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:  1 #################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\surrogate\\lib\\site-packages\\ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS1:  Degree 1 e_LOO 3.836931236001603e-06 Pf_ref 0.032 Pf 0.06413 CoV 0.01210\n",
      "LS2:  Degree 1 e_LOO 4.240468345252064e-05 Pf_ref 0.14862 Pf 0.16308 CoV 0.00720\n",
      "number of training points:  11 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.046620807954644565 Pf_ref 0.03198 Pf 0.13326 CoV 0.00810\n",
      "LS2:  Degree 2 e_LOO 0.03357610546351106 Pf_ref 0.14861 Pf 0.13187 CoV 0.00810\n",
      "number of training points:  12 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.016214618248466598 Pf_ref 0.03123 Pf 0.13193 CoV 0.00810\n",
      "LS2:  Degree 2 e_LOO 0.08277592172385313 Pf_ref 0.15097 Pf 0.11813 CoV 0.00860\n",
      "number of training points:  13 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0392053227429953 Pf_ref 0.0312 Pf 0.05091 CoV 0.01370\n",
      "LS2:  Degree 1 e_LOO 0.002578679943607183 Pf_ref 0.14773 Pf 0.1142 CoV 0.00880\n",
      "number of training points:  14 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.016481263749379624 Pf_ref 0.03103 Pf 0.05289 CoV 0.01340\n",
      "LS2:  Degree 2 e_LOO 0.0006953104894688213 Pf_ref 0.14761 Pf 0.10325 CoV 0.00930\n",
      "number of training points:  15 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0011476682754023259 Pf_ref 0.03075 Pf 0.04823 CoV 0.01400\n",
      "LS2:  Degree 1 e_LOO 4.569051750865592e-05 Pf_ref 0.14861 Pf 0.13699 CoV 0.00790\n",
      "number of training points:  16 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.11582511407654801 Pf_ref 0.03006 Pf 0.0551 CoV 0.01310\n",
      "LS2:  Degree 1 e_LOO 0.09630436870091352 Pf_ref 0.14795 Pf 0.1163 CoV 0.00870\n",
      "number of training points:  17 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.01526459433161285 Pf_ref 0.03148 Pf 0.03895 CoV 0.01570\n",
      "LS2:  Degree 2 e_LOO 0.00024102367172837874 Pf_ref 0.15038 Pf 0.11662 CoV 0.00870\n",
      "number of training points:  18 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.000564616372864337 Pf_ref 0.0305 Pf 0.0884 CoV 0.01020\n",
      "LS2:  Degree 3 e_LOO 0.00035028469998474196 Pf_ref 0.14768 Pf 0.08807 CoV 0.01020\n",
      "number of training points:  19 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00045831149775243604 Pf_ref 0.03116 Pf 0.03599 CoV 0.01640\n",
      "LS2:  Degree 3 e_LOO 3.860101691459242e-06 Pf_ref 0.14898 Pf 0.0927 CoV 0.00990\n",
      "number of training points:  20 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.005206874564939456 Pf_ref 0.03163 Pf 0.04022 CoV 0.01540\n",
      "LS2:  Degree 3 e_LOO 9.307522110707906e-05 Pf_ref 0.14837 Pf 0.0948 CoV 0.00980\n",
      "number of training points:  21 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.001405352337499859 Pf_ref 0.03131 Pf 0.08205 CoV 0.01060\n",
      "LS2:  Degree 3 e_LOO 0.001662504079748656 Pf_ref 0.14718 Pf 0.07059 CoV 0.01150\n",
      "number of training points:  22 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0021425782862067523 Pf_ref 0.03088 Pf 0.08447 CoV 0.01040\n",
      "LS2:  Degree 3 e_LOO 0.0034532040171053723 Pf_ref 0.14657 Pf 0.05559 CoV 0.01300\n",
      "number of training points:  23 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0004087829759256866 Pf_ref 0.03079 Pf 0.0846 CoV 0.01040\n",
      "LS2:  Degree 4 e_LOO 0.0019917441096782467 Pf_ref 0.14854 Pf 0.11673 CoV 0.00870\n",
      "number of training points:  24 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 7.318311915661232e-05 Pf_ref 0.03148 Pf 0.0835 CoV 0.01050\n",
      "LS2:  Degree 4 e_LOO 0.00032129106159708114 Pf_ref 0.14774 Pf 0.10151 CoV 0.00940\n",
      "number of training points:  25 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 3.6394991312898042e-06 Pf_ref 0.03074 Pf 0.08499 CoV 0.01040\n",
      "LS2:  Degree 4 e_LOO 0.0021124483578357084 Pf_ref 0.15036 Pf 0.10858 CoV 0.00910\n",
      "number of training points:  26 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00020866763933410115 Pf_ref 0.0318 Pf 0.08298 CoV 0.01050\n",
      "LS2:  Degree 4 e_LOO 0.0002217777035862072 Pf_ref 0.14961 Pf 0.10408 CoV 0.00930\n",
      "number of training points:  27 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00023797663445034657 Pf_ref 0.03088 Pf 0.09558 CoV 0.00970\n",
      "LS2:  Degree 4 e_LOO 0.0012953574452727375 Pf_ref 0.14942 Pf 0.10409 CoV 0.00930\n",
      "number of training points:  28 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 9.439013054272101e-05 Pf_ref 0.0313 Pf 0.09517 CoV 0.00980\n",
      "LS2:  Degree 2 e_LOO 0.005460386842836049 Pf_ref 0.14955 Pf 0.08822 CoV 0.01020\n",
      "number of training points:  29 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 5.1325877950565364e-05 Pf_ref 0.03192 Pf 0.09333 CoV 0.00990\n",
      "LS2:  Degree 2 e_LOO 0.005373635970474987 Pf_ref 0.14875 Pf 0.0629 CoV 0.01220\n",
      "number of training points:  30 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0009239298231315129 Pf_ref 0.03101 Pf 0.0727 CoV 0.01130\n",
      "LS2:  Degree 3 e_LOO 0.0012973299020811143 Pf_ref 0.14716 Pf 0.05595 CoV 0.01300\n",
      "number of training points:  31 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00028357709920923786 Pf_ref 0.03024 Pf 0.06972 CoV 0.01160\n",
      "LS2:  Degree 3 e_LOO 0.001212546903305105 Pf_ref 0.14893 Pf 0.05792 CoV 0.01280\n",
      "number of training points:  32 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 2.3374991932004925e-05 Pf_ref 0.03115 Pf 0.06976 CoV 0.01150\n",
      "LS2:  Degree 3 e_LOO 0.0006547984196143615 Pf_ref 0.14804 Pf 0.05682 CoV 0.01290\n",
      "number of training points:  33 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0013201954695045428 Pf_ref 0.03139 Pf 0.08126 CoV 0.01060\n",
      "LS2:  Degree 3 e_LOO 0.00039961347169995275 Pf_ref 0.14915 Pf 0.05524 CoV 0.01310\n",
      "number of training points:  34 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 0.0011957670039968223 Pf_ref 0.03281 Pf 0.05316 CoV 0.01330\n",
      "LS2:  Degree 3 e_LOO 0.0002764030984153686 Pf_ref 0.14938 Pf 0.05903 CoV 0.01260\n",
      "number of training points:  35 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0006142565119699268 Pf_ref 0.03111 Pf 0.05048 CoV 0.01370\n",
      "LS2:  Degree 3 e_LOO 0.0016123749938556724 Pf_ref 0.14781 Pf 0.05919 CoV 0.01260\n",
      "number of training points:  36 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0003300486752374296 Pf_ref 0.0315 Pf 0.03073 CoV 0.01780\n",
      "LS2:  Degree 3 e_LOO 0.001370459089508313 Pf_ref 0.14797 Pf 0.05907 CoV 0.01260\n",
      "number of training points:  37 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 6.269590004503456e-06 Pf_ref 0.03141 Pf 0.02987 CoV 0.01800\n",
      "LS2:  Degree 3 e_LOO 0.0009976837132507385 Pf_ref 0.14852 Pf 0.05999 CoV 0.01250\n",
      "number of training points:  38 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0001469606654235143 Pf_ref 0.03156 Pf 0.02887 CoV 0.01830\n",
      "LS2:  Degree 3 e_LOO 0.0006833112419076843 Pf_ref 0.14797 Pf 0.05823 CoV 0.01270\n",
      "number of training points:  39 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 6.656094756915922e-05 Pf_ref 0.03104 Pf 0.02892 CoV 0.01830\n",
      "LS2:  Degree 3 e_LOO 0.0005377007051071293 Pf_ref 0.14915 Pf 0.05928 CoV 0.01260\n",
      "number of training points:  40 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 8.461023758613162e-07 Pf_ref 0.03148 Pf 0.02388 CoV 0.02020\n",
      "LS2:  Degree 3 e_LOO 0.001294547670391749 Pf_ref 0.14861 Pf 0.05674 CoV 0.01290\n",
      "number of training points:  41 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 2.129973639033598e-06 Pf_ref 0.03114 Pf 0.02392 CoV 0.02020\n",
      "LS2:  Degree 3 e_LOO 0.0005603672465675489 Pf_ref 0.14763 Pf 0.05794 CoV 0.01280\n",
      "number of training points:  42 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00017490885141854088 Pf_ref 0.03163 Pf 0.02411 CoV 0.02010\n",
      "LS2:  Degree 3 e_LOO 4.7948250033053183e-05 Pf_ref 0.14794 Pf 0.05693 CoV 0.01290\n",
      "number of training points:  43 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 2.326195016935078e-06 Pf_ref 0.03104 Pf 0.02401 CoV 0.02020\n",
      "LS2:  Degree 3 e_LOO 6.894501382644393e-05 Pf_ref 0.14935 Pf 0.05844 CoV 0.01270\n",
      "number of training points:  44 -------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS1:  Degree 3 e_LOO 3.5795824472839923e-06 Pf_ref 0.03065 Pf 0.02235 CoV 0.02090\n",
      "LS2:  Degree 3 e_LOO 0.00013177247121531427 Pf_ref 0.14828 Pf 0.06509 CoV 0.01200\n",
      "number of training points:  45 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00022042912202636353 Pf_ref 0.03205 Pf 0.02338 CoV 0.02040\n",
      "LS2:  Degree 3 e_LOO 3.715089806399571e-05 Pf_ref 0.14768 Pf 0.06506 CoV 0.01200\n",
      "number of training points:  46 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0002650687644817312 Pf_ref 0.03255 Pf 0.02393 CoV 0.02020\n",
      "LS2:  Degree 3 e_LOO 2.040493265214328e-05 Pf_ref 0.14884 Pf 0.07981 CoV 0.01070\n",
      "number of training points:  47 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 9.194838528816545e-05 Pf_ref 0.03117 Pf 0.0233 CoV 0.02050\n",
      "LS2:  Degree 3 e_LOO 6.416148887256715e-06 Pf_ref 0.14739 Pf 0.07743 CoV 0.01090\n",
      "number of training points:  48 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00013079358696056368 Pf_ref 0.03037 Pf 0.02283 CoV 0.02070\n",
      "LS2:  Degree 3 e_LOO 7.947691023081555e-06 Pf_ref 0.14729 Pf 0.07869 CoV 0.01080\n",
      "number of training points:  49 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00022036271911250822 Pf_ref 0.03209 Pf 0.02396 CoV 0.02020\n",
      "LS2:  Degree 3 e_LOO 1.625467493459004e-06 Pf_ref 0.14815 Pf 0.11241 CoV 0.00890\n",
      "number of training points:  50 -------------------------------------------------\n",
      "Experiment:  2 #################################################################\n",
      "LS1:  Degree 2 e_LOO 0.001313252195165944 Pf_ref 0.03095 Pf 0.04098 CoV 0.01530\n",
      "LS2:  Degree 2 e_LOO 9.380555468327358e-05 Pf_ref 0.14787 Pf 0.13513 CoV 0.00800\n",
      "number of training points:  11 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.0025076444048637613 Pf_ref 0.03124 Pf 0.11442 CoV 0.00880\n",
      "LS2:  Degree 1 e_LOO 0.5952081707052447 Pf_ref 0.14722 Pf 0.04867 CoV 0.01400\n",
      "number of training points:  12 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.008151781469991742 Pf_ref 0.03094 Pf 0.13015 CoV 0.00820\n",
      "LS2:  Degree 3 e_LOO 0.32572391076228296 Pf_ref 0.1487 Pf 0.13912 CoV 0.00790\n",
      "number of training points:  13 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.04509677662943634 Pf_ref 0.03142 Pf 0.07678 CoV 0.01100\n",
      "LS2:  Degree 1 e_LOO 0.24070940837216392 Pf_ref 0.14823 Pf 0.03953 CoV 0.01560\n",
      "number of training points:  14 -------------------------------------------------\n",
      "LS1:  Degree 1 e_LOO 0.00013486059182721326 Pf_ref 0.03202 Pf 0.06811 CoV 0.01170\n",
      "LS2:  Degree 1 e_LOO 0.038578996433397496 Pf_ref 0.14898 Pf 0.05957 CoV 0.01260\n",
      "number of training points:  15 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.02019216034550021 Pf_ref 0.03054 Pf 0.03056 CoV 0.01780\n",
      "LS2:  Degree 2 e_LOO 0.004112077934848604 Pf_ref 0.14906 Pf 0.03679 CoV 0.01620\n",
      "number of training points:  16 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.019463797416755278 Pf_ref 0.03145 Pf 0.02929 CoV 0.01820\n",
      "LS2:  Degree 3 e_LOO 0.0005010462486108071 Pf_ref 0.14788 Pf 0.07753 CoV 0.01090\n",
      "number of training points:  17 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 1.9071489841833116e-05 Pf_ref 0.03245 Pf 0.03648 CoV 0.01630\n",
      "LS2:  Degree 2 e_LOO 0.0054285609083194915 Pf_ref 0.14977 Pf 0.02669 CoV 0.01910\n",
      "number of training points:  18 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00029233779637277186 Pf_ref 0.03165 Pf 0.03773 CoV 0.01600\n",
      "LS2:  Degree 3 e_LOO 0.008510348223175824 Pf_ref 0.14953 Pf 0.07623 CoV 0.01100\n",
      "number of training points:  19 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.006042709262529015 Pf_ref 0.032 Pf 0.02113 CoV 0.02150\n",
      "LS2:  Degree 3 e_LOO 0.0020390577570597703 Pf_ref 0.147 Pf 0.09529 CoV 0.00970\n",
      "number of training points:  20 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.001511033243828453 Pf_ref 0.03088 Pf 0.03936 CoV 0.01560\n",
      "LS2:  Degree 2 e_LOO 0.018835544810044704 Pf_ref 0.14786 Pf 0.03792 CoV 0.01590\n",
      "number of training points:  21 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.005553229874472041 Pf_ref 0.03139 Pf 0.06142 CoV 0.01240\n",
      "LS2:  Degree 4 e_LOO 0.0029380777503322654 Pf_ref 0.14631 Pf 0.13926 CoV 0.00790\n",
      "number of training points:  22 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0003929044220962257 Pf_ref 0.03079 Pf 0.051 CoV 0.01360\n",
      "LS2:  Degree 3 e_LOO 0.0005549114122024407 Pf_ref 0.14998 Pf 0.01754 CoV 0.02370\n",
      "number of training points:  23 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0003776730977835084 Pf_ref 0.03169 Pf 0.05645 CoV 0.01290\n",
      "LS2:  Degree 3 e_LOO 0.00022429132376731948 Pf_ref 0.14859 Pf 0.01794 CoV 0.02340\n",
      "number of training points:  24 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0007689401828437714 Pf_ref 0.03134 Pf 0.06362 CoV 0.01210\n",
      "LS2:  Degree 3 e_LOO 1.7328493575392734e-06 Pf_ref 0.14909 Pf 0.00827 CoV 0.03460\n",
      "number of training points:  25 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0010521798818935487 Pf_ref 0.03178 Pf 0.06669 CoV 0.01180\n",
      "LS2:  Degree 3 e_LOO 0.0001674847052798277 Pf_ref 0.14866 Pf 0.00668 CoV 0.03860\n",
      "number of training points:  26 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 0.000565192368275865 Pf_ref 0.03123 Pf 0.09758 CoV 0.00960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\surrogate\\lib\\site-packages\\scipy\\optimize\\optimize.py:283: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  \"minimize step, clipping to bounds\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS2:  Degree 3 e_LOO 1.9658281255334124e-05 Pf_ref 0.14919 Pf 0.00879 CoV 0.03360\n",
      "number of training points:  27 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0002197216941082794 Pf_ref 0.03043 Pf 0.05773 CoV 0.01280\n",
      "LS2:  Degree 3 e_LOO 4.5071720238985615e-05 Pf_ref 0.14733 Pf 0.01127 CoV 0.02960\n",
      "number of training points:  28 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0017871079513898244 Pf_ref 0.03103 Pf 0.07457 CoV 0.01110\n",
      "LS2:  Degree 3 e_LOO 3.986480516514611e-05 Pf_ref 0.14956 Pf 0.01117 CoV 0.02980\n",
      "number of training points:  29 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.000884118933772588 Pf_ref 0.03168 Pf 0.05343 CoV 0.01330\n",
      "LS2:  Degree 3 e_LOO 9.363860758973731e-06 Pf_ref 0.14839 Pf 0.01182 CoV 0.02890\n",
      "number of training points:  30 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 7.593746453878194e-06 Pf_ref 0.03065 Pf 0.02675 CoV 0.01910\n",
      "LS2:  Degree 4 e_LOO 6.235098010488018e-07 Pf_ref 0.14779 Pf 0.02829 CoV 0.01850\n",
      "number of training points:  31 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00018620558234869216 Pf_ref 0.03108 Pf 0.06096 CoV 0.01240\n",
      "LS2:  Degree 2 e_LOO 0.0002232738411553286 Pf_ref 0.14705 Pf 0.03176 CoV 0.01750\n",
      "number of training points:  32 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.00010699520600371215 Pf_ref 0.03182 Pf 0.06278 CoV 0.01220\n",
      "LS2:  Degree 2 e_LOO 7.275599958278384e-05 Pf_ref 0.14765 Pf 0.03339 CoV 0.01700\n",
      "number of training points:  33 -------------------------------------------------\n",
      "LS1:  Degree 2 e_LOO 0.0002609959571088533 Pf_ref 0.03072 Pf 0.06013 CoV 0.01250\n",
      "LS2:  Degree 2 e_LOO 8.38828407143642e-06 Pf_ref 0.14904 Pf 0.03296 CoV 0.01710\n",
      "number of training points:  34 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00012298249779509873 Pf_ref 0.03096 Pf 0.01346 CoV 0.02710\n",
      "LS2:  Degree 2 e_LOO 2.5364010805572703e-06 Pf_ref 0.14854 Pf 0.02919 CoV 0.01820\n",
      "number of training points:  35 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 8.135503266733937e-05 Pf_ref 0.03207 Pf 0.01262 CoV 0.02800\n",
      "LS2:  Degree 3 e_LOO 1.9404796815221066e-06 Pf_ref 0.14881 Pf 0.02149 CoV 0.02130\n",
      "number of training points:  36 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 2.023916501690506e-08 Pf_ref 0.02994 Pf 0.01377 CoV 0.02680\n",
      "LS2:  Degree 4 e_LOO 1.549725342808787e-07 Pf_ref 0.15106 Pf 0.02412 CoV 0.02010\n",
      "number of training points:  37 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 9.044464646281354e-05 Pf_ref 0.03025 Pf 0.01293 CoV 0.02760\n",
      "LS2:  Degree 3 e_LOO 2.3062286904351714e-05 Pf_ref 0.14771 Pf 0.0196 CoV 0.02240\n",
      "number of training points:  38 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00025494910333863266 Pf_ref 0.0323 Pf 0.015 CoV 0.02560\n",
      "LS2:  Degree 3 e_LOO 0.0002389103349738235 Pf_ref 0.14775 Pf 0.02003 CoV 0.02210\n",
      "number of training points:  39 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.0002546653090860152 Pf_ref 0.03192 Pf 0.01234 CoV 0.02830\n",
      "LS2:  Degree 3 e_LOO 0.00018254583583061847 Pf_ref 0.15033 Pf 0.02018 CoV 0.02200\n",
      "number of training points:  40 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00013831402101922863 Pf_ref 0.0316 Pf 0.01251 CoV 0.02810\n",
      "LS2:  Degree 3 e_LOO 9.445605217208124e-07 Pf_ref 0.14698 Pf 0.02119 CoV 0.02150\n",
      "number of training points:  41 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 3.993941642808028e-06 Pf_ref 0.03109 Pf 0.01224 CoV 0.02840\n",
      "LS2:  Degree 4 e_LOO 2.5953706320628786e-06 Pf_ref 0.1486 Pf 0.06845 CoV 0.01170\n",
      "number of training points:  42 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 1.6644404485168414e-05 Pf_ref 0.03077 Pf 0.01231 CoV 0.02830\n",
      "LS2:  Degree 4 e_LOO 4.989547471104446e-07 Pf_ref 0.14983 Pf 0.0669 CoV 0.01180\n",
      "number of training points:  43 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00020371716172934502 Pf_ref 0.0311 Pf 0.01244 CoV 0.02820\n",
      "LS2:  Degree 3 e_LOO 4.822203694334588e-06 Pf_ref 0.1482 Pf 0.06405 CoV 0.01210\n",
      "number of training points:  44 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00018979325891034407 Pf_ref 0.03005 Pf 0.01127 CoV 0.02960\n",
      "LS2:  Degree 3 e_LOO 1.1120580908323106e-05 Pf_ref 0.14734 Pf 0.06415 CoV 0.01210\n",
      "number of training points:  45 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00021089862400480274 Pf_ref 0.03122 Pf 0.01195 CoV 0.02880\n",
      "LS2:  Degree 4 e_LOO 1.5806611407617996e-05 Pf_ref 0.14893 Pf 0.06757 CoV 0.01170\n",
      "number of training points:  46 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00020834194085009997 Pf_ref 0.03263 Pf 0.01231 CoV 0.02830\n",
      "LS2:  Degree 4 e_LOO 1.3520245306803156e-05 Pf_ref 0.14834 Pf 0.06132 CoV 0.01240\n",
      "number of training points:  47 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00016594215901492184 Pf_ref 0.03112 Pf 0.01194 CoV 0.02880\n",
      "LS2:  Degree 3 e_LOO 2.1877934016746826e-05 Pf_ref 0.14835 Pf 0.07735 CoV 0.01090\n",
      "number of training points:  48 -------------------------------------------------\n",
      "LS1:  Degree 3 e_LOO 0.00025583151645688435 Pf_ref 0.03123 Pf 0.01217 CoV 0.02850\n",
      "LS2:  Degree 4 e_LOO 9.719344101365767e-07 Pf_ref 0.14899 Pf 0.08314 CoV 0.01050\n",
      "number of training points:  49 -------------------------------------------------\n",
      "LS1:  Degree 4 e_LOO 4.823351673565688e-05 Pf_ref 0.03223 Pf 0.01245 CoV 0.02820\n",
      "LS2:  Degree 3 e_LOO 0.0003079552093778538 Pf_ref 0.1464 Pf 0.08427 CoV 0.01040\n",
      "number of training points:  50 -------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "number_experiments = 15\n",
    "number_active_points = 40\n",
    "\n",
    "results_file = '_CATBDiff_EFF_' + str(number_active_points)   # index for results files\n",
    "\n",
    "for experiments in range(number_experiments):\n",
    "    print('Experiment: ', experiments+1 , '#################################################################' )\n",
    "    \n",
    "    ActiveTrain_1 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "    ActiveTrain_2 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "\n",
    "    #INITIAL design of experiments (LHS) passive training ####################################\n",
    "\n",
    "    n = 10       # number of initial sampling\n",
    "\n",
    "    xn = np.zeros((int(n), dim))      #normalized training points\n",
    "    xr = np.zeros((int(n), dim))      #scaled training points\n",
    "    yn = np.zeros((int(n)))           #observations\n",
    "\n",
    "    # Check the variables limits for space-filling distribution\n",
    "    Xdoe = build.space_filling_lhs( {'x1':[-1, 1],      \n",
    "                                     'x2':[-1, 1],} , \n",
    "                                      num_samples = n )\n",
    "    #------------------------------------------------------------\n",
    "    xn[:,0] = Xdoe['x1']\n",
    "    xn[:,1] = Xdoe['x2']\n",
    "    xr[:,0] = PCK1.scalehermite(xn[:,0], x1mean, x1sigma)\n",
    "    xr[:,1] = PCK1.scalehermite(xn[:,1], x2mean, x2sigma)\n",
    "\n",
    "    yn_1 = function_1(xr)[0]\n",
    "    yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    # kernel hyperparameters-------------------------------------\n",
    "    v = 5/2        #Gaussian process\n",
    "    #truncation term-------------------------------------\n",
    "    p_max = 5  #for each variable â†’ same truncation , degree of expansion\n",
    "    \n",
    "    for points in range(number_active_points):\n",
    "\n",
    "        # Selecting the smallest e_loo model (length and order)\n",
    "        \n",
    "        mse_results = np.zeros(p_max-1)\n",
    "        opt_length_it = np.zeros(p_max-1)\n",
    "        eloo_results = np.zeros(p_max-1)\n",
    "\n",
    "        mean_loo = np.zeros(len(xn))\n",
    "        var_loo = np.zeros(len(xn))\n",
    "\n",
    "        dist = PCK1.distance(xn, xn)\n",
    "        lmax = np.max(dist)\n",
    "        lmin = np.min(dist[dist!=0])\n",
    "        bounds = [(lmin, lmax)]\n",
    "\n",
    "        results = dict()\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 1 #############################################\n",
    "    \n",
    "#         print('AT Limit state 1 ')\n",
    "\n",
    "        ModelName_1 = 'PCK1_' + str(len(xn))\n",
    "        \n",
    "        ModelName_1 = PC_Kriging(config)\n",
    "\n",
    "        # yn is changing for each LS (inside L_Object )\n",
    "        yn = yn_1    #observations\n",
    "        YN = YN_1    #test points\n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "\n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "\n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar1 = ModelName_1.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_1.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)    #selected based 'eloo' instead 'mse'\n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar1 = ModelName_1.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        ## Pool of samples for MCS -----------------------------------\n",
    "        MCS_samples = 100000\n",
    "\n",
    "        MCinputs_norm = np.zeros((int(MCS_samples), dim))\n",
    "        MCinputs = np.zeros((int(MCS_samples), dim))\n",
    "\n",
    "        MCinputs_norm[:,0] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "        MCinputs_norm[:,1] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "\n",
    "        MCinputs[:,0] = PCK1.scalehermite(MCinputs_norm[:,0], x1mean, x1sigma)  \n",
    "        MCinputs[:,1] = PCK1.scalehermite(MCinputs_norm[:,1], x2mean, x2sigma)  \n",
    "    \n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_1 = function_1(MCinputs)[0]  \n",
    "        fail_samples_1 = np.sum(ymc_1 < 0 )\n",
    "        Pf_ref_1 = fail_samples_1 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_1, varMC_1 = ModelName_1.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_1 = np.sum(np.asarray(meanMC_1) < 0 )\n",
    "        fail_prob_SUMO_1 = fail_samples_SUMO_1 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_1 ) / (fail_prob_SUMO_1 * MCS_samples) )\n",
    "\n",
    "        print('LS1: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results), 'Pf_ref', Pf_ref_1 ,'Pf', fail_prob_SUMO_1 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_1[str(len(xn))+'points'] = ModelName_1 , fail_prob_SUMO_1 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 2 #############################################\n",
    "        \n",
    "#         print('Training Limit state 2 ')\n",
    "        \n",
    "        ModelName_2 = 'PCK2_' + str(len(xn))\n",
    "        \n",
    "        ModelName_2 = PC_Kriging(config)\n",
    "        \n",
    "        # yn is changing for each LS \n",
    "        yn = yn_2\n",
    "        YN = YN_2\n",
    "        # Selecting the smallest e_loo model (length and order) \n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "            \n",
    "            # results = dict()\n",
    "            # bounds = [(lmin, lmax)]\n",
    "            \n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "\n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar2 = ModelName_2.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_2.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)    \n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar2 = ModelName_2.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_2 = function_2(MCinputs)[0]  \n",
    "        fail_samples_2 = np.sum(ymc_2 < 0 )\n",
    "        Pf_ref_2 = fail_samples_2 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_2, varMC_2 = ModelName_2.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_2 = np.sum(np.asarray(meanMC_2) < 0 )\n",
    "        fail_prob_SUMO_2 = fail_samples_SUMO_2 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_2 ) / (fail_prob_SUMO_2 * MCS_samples) )        \n",
    "        \n",
    "        print('LS2: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results) , 'Pf_ref', Pf_ref_2 ,'Pf', fail_prob_SUMO_2 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_2[str(len(xn))+'points'] = ModelName_2 , fail_prob_SUMO_2 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "\n",
    "        # ##############################################################################\n",
    "                \n",
    "        if ( points == 0 ):   \n",
    "            meanMC = meanMC_1\n",
    "            varMC = varMC_1               \n",
    "            print ('LS 1')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        elif ( fail_prob_SUMO_1 == 0 ): \n",
    "            meanMC = meanMC_1\n",
    "            varMC = varMC_1              \n",
    "            print ('LS 1')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        elif ( fail_prob_SUMO_2 == 0 ): \n",
    "            meanMC = meanMC_2\n",
    "            varMC = varMC_2                \n",
    "            print ('LS 2')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        else:\n",
    "            Pf1_new = fail_prob_SUMO_1\n",
    "            Pf2_new = fail_prob_SUMO_2\n",
    "\n",
    "            B1_old = - norm.ppf ( Pf1_old )\n",
    "            B2_old = - norm.ppf ( Pf2_old )\n",
    "\n",
    "            B1_new = - norm.ppf ( Pf1_new )\n",
    "            B2_new = - norm.ppf ( Pf2_new )\n",
    "\n",
    "            B_error1 = abs(B1_old - B1_new ) / B1_old\n",
    "            B_error2 = abs(B2_old - B2_new ) / B2_old\n",
    "\n",
    "            if (B_error1 > B_error2):\n",
    "\n",
    "                meanMC = meanMC_1\n",
    "                varMC = varMC_1               \n",
    "                print (B_error1, B_error2, 'LS 1')\n",
    "\n",
    "                Pf1_old = fail_prob_SUMO_1\n",
    "                Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "            else:\n",
    "\n",
    "                meanMC = meanMC_2\n",
    "                varMC = varMC_2               \n",
    "                print (B_error1, B_error2, 'LS 2')\n",
    "\n",
    "                Pf1_old = fail_prob_SUMO_1\n",
    "                Pf2_old = fail_prob_SUMO_2\n",
    "        \n",
    "        \n",
    "        ### Evaluating new points\n",
    "        eff = EFF(meanMC.reshape(-1), varMC.reshape(-1) , 0 )  #(mean, variance, target) \n",
    "        \n",
    "        xr = np.append(xr, MCinputs[np.argmax(eff)]).reshape(-1,2)\n",
    "        xn = np.append(xn, MCinputs_norm[np.argmax(eff)]).reshape(-1,2)\n",
    "        \n",
    "        yn_1 = function_1(xr)[0]\n",
    "        yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    \n",
    "        print('number of training points: ', len(xn),'-------------------------------------------------')\n",
    "    filename1 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS1.sav'\n",
    "\n",
    "    pickle.dump(ActiveTrain_1, open(filename1, 'wb'))\n",
    "    \n",
    "    filename2 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS2.sav'\n",
    "    pickle.dump(ActiveTrain_2, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5ac89",
   "metadata": {},
   "source": [
    "# Combined training - U - LOO - 2 LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30596ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_experiments = 13    \n",
    "number_active_points = 40\n",
    "\n",
    "results_file = '_CAT_ULOO_' + str(number_active_points)   # index for results files\n",
    "\n",
    "for experiments in range(number_experiments):\n",
    "    print('Experiment: ', experiments+1 , '#################################################################' )\n",
    "    \n",
    "    ActiveTrain_1 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "    ActiveTrain_2 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "\n",
    "    #INITIAL design of experiments (LHS) passive training ####################################\n",
    "\n",
    "    n = 10       # number of initial sampling\n",
    "\n",
    "    xn = np.zeros((int(n), dim))      #normalized training points\n",
    "    xr = np.zeros((int(n), dim))      #scaled training points\n",
    "    yn = np.zeros((int(n)))           #observations\n",
    "\n",
    "    # Check the variables limits for space-filling distribution\n",
    "    Xdoe = build.space_filling_lhs( {'x1':[-1, 1],      \n",
    "                                     'x2':[-1, 1],} , \n",
    "                                      num_samples = n )\n",
    "    #------------------------------------------------------------\n",
    "    xn[:,0] = Xdoe['x1']\n",
    "    xn[:,1] = Xdoe['x2']\n",
    "    xr[:,0] = PCK1.scalehermite(xn[:,0], x1mean, x1sigma)\n",
    "    xr[:,1] = PCK1.scalehermite(xn[:,1], x2mean, x2sigma)\n",
    "\n",
    "    yn_1 = function_1(xr)[0]\n",
    "    yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    # kernel hyperparameters-------------------------------------\n",
    "    v = 5/2        #Gaussian process\n",
    "    #truncation term-------------------------------------\n",
    "    p_max = 5  #for each variable â†’ same truncation , degree of expansion\n",
    "    \n",
    "    for points in range(number_active_points):\n",
    "\n",
    "        # Selecting the smallest e_loo model (length and order)\n",
    "        \n",
    "        mse_results = np.zeros(p_max-1)\n",
    "        opt_length_it = np.zeros(p_max-1)\n",
    "        eloo_results = np.zeros(p_max-1)\n",
    "\n",
    "        mean_loo = np.zeros(len(xn))\n",
    "        var_loo = np.zeros(len(xn))\n",
    "        e_lcv = np.zeros(len(xn))\n",
    "        sumat_1 = np.zeros((len(xn),(p_max-1)))\n",
    "        sumat_2 = np.zeros((len(xn),(p_max-1)))\n",
    "\n",
    "        dist = PCK1.distance(xr, xr)\n",
    "        lmax = np.max(dist)\n",
    "        lmin = np.min(dist[dist!=0])\n",
    "        bounds = [(lmin, lmax)]\n",
    "\n",
    "        results = dict()\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 1 #############################################\n",
    "    \n",
    "#         print('AT Limit state 1 ')\n",
    "\n",
    "        ModelName_1 = 'PCK1_' + str(len(xn))\n",
    "        \n",
    "        ModelName_1 = PC_Kriging(config)\n",
    "\n",
    "        # yn is changing for each LS (inside L_Object )\n",
    "        yn = yn_1    #observations\n",
    "        YN = YN_1    #test points\n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "\n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "                \n",
    "                e_lcv[i] = (yn[i] - mean_loo[i])**2\n",
    "\n",
    "            sumat_1[:,p-1] = np.divide(e_lcv, var_loo)      #LOO CV as proposed by Le Gratiet\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              \n",
    "            #sumat_1[:,p-1] = np.divide(e_loo, var_loo)      #LOO CV squared errors with MSE\n",
    "            \n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar1 = ModelName_1.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_1.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)    #selected based 'eloo' instead 'mse'\n",
    "        opt_1 = opt \n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar1 = ModelName_1.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        ## Pool of samples for MCS -----------------------------------\n",
    "        MCS_samples = 100000\n",
    "        LOOCV_1 = np.zeros(MCS_samples)\n",
    "        LOOCV_2 = np.zeros(MCS_samples)\n",
    "\n",
    "        MCinputs_norm = np.zeros((int(MCS_samples), dim))\n",
    "        MCinputs = np.zeros((int(MCS_samples), dim))\n",
    "\n",
    "        MCinputs_norm[:,0] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "        MCinputs_norm[:,1] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "\n",
    "        MCinputs[:,0] = PCK1.scalehermite(MCinputs_norm[:,0], x1mean, x1sigma)  \n",
    "        MCinputs[:,1] = PCK1.scalehermite(MCinputs_norm[:,1], x2mean, x2sigma)  \n",
    "    \n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_1 = function_1(MCinputs)[0]  \n",
    "        fail_samples_1 = np.sum(ymc_1 < 0 )\n",
    "        Pf_ref_1 = fail_samples_1 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_1, varMC_1 = ModelName_1.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_1 = np.sum(np.asarray(meanMC_1) < 0 )\n",
    "        fail_prob_SUMO_1 = fail_samples_SUMO_1 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_1 ) / (fail_prob_SUMO_1 * MCS_samples) )\n",
    "\n",
    "        print('LS1: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results), 'Pf_ref', Pf_ref_1 ,'Pf', fail_prob_SUMO_1 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_1[str(len(xn))+'points'] = ModelName_1 , fail_prob_SUMO_1 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 2 #############################################\n",
    "        \n",
    "#         print('Training Limit state 2 ')\n",
    "        \n",
    "        ModelName_2 = 'PCK2_' + str(len(xn))\n",
    "        \n",
    "        ModelName_2 = PC_Kriging(config)\n",
    "        \n",
    "        # yn is changing for each LS \n",
    "        yn = yn_2\n",
    "        YN = YN_2\n",
    "        # Selecting the smallest e_loo model (length and order) \n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "            \n",
    "            # results = dict()\n",
    "            # bounds = [(lmin, lmax)]\n",
    "            \n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "            sumat_2[:,p-1] = np.divide(e_loo, var_loo)\n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar2 = ModelName_2.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_2.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)\n",
    "        opt_2 = opt  \n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar2 = ModelName_2.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_2 = function_2(MCinputs)[0]  \n",
    "        fail_samples_2 = np.sum(ymc_2 < 0 )\n",
    "        Pf_ref_2 = fail_samples_2 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_2, varMC_2 = ModelName_2.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_2 = np.sum(np.asarray(meanMC_2) < 0 )\n",
    "        fail_prob_SUMO_2 = fail_samples_SUMO_2 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_2 ) / (fail_prob_SUMO_2 * MCS_samples) )        \n",
    "        \n",
    "        print('LS2: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results) , 'Pf_ref', Pf_ref_2 ,'Pf', fail_prob_SUMO_2 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_2[str(len(xn))+'points'] = ModelName_2 , fail_prob_SUMO_2 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "\n",
    "        # ##############################################################################\n",
    "        \n",
    "        # LOO CV errors ###################################################\n",
    "        #variance enhancement based LOO CV erros around voronoi cells\n",
    "        for k in range (0, MCS_samples):               \n",
    "            voro = VoronoiCell(MCinputs[k], xr)\n",
    "            LOOCV_1[k]= varMC_1[k]*(1+sumat_1[voro, opt_1])\n",
    "            LOOCV_2[k]= varMC_2[k]*(1+sumat_2[voro, opt_2])\n",
    "            \n",
    "        ### Evaluating new points\n",
    "        U_f_1 = U_function(meanMC_1.reshape(-1), LOOCV_1.reshape(-1))\n",
    "        U_f_2 = U_function(meanMC_2.reshape(-1), LOOCV_2.reshape(-1))\n",
    "        \n",
    "        U_f = (U_f_1 + U_f_2) / 2    #average U\n",
    "        \n",
    "        xr = np.append(xr, MCinputs[np.argmin(U_f)]).reshape(-1,2)\n",
    "        xn = np.append(xn, MCinputs_norm[np.argmin(U_f)]).reshape(-1,2)\n",
    "        \n",
    "        yn_1 = function_1(xr)[0]\n",
    "        yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    \n",
    "        print('number of training points: ', len(xn),'-------------------------------------------------')\n",
    "    filename1 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS1.sav'\n",
    "\n",
    "    pickle.dump(ActiveTrain_1, open(filename1, 'wb'))\n",
    "    \n",
    "    filename2 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS2.sav'\n",
    "    pickle.dump(ActiveTrain_2, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a06a0",
   "metadata": {},
   "source": [
    "# Combined training - EFF - LOO - 2 LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_experiments = 15    \n",
    "number_active_points = 40\n",
    "\n",
    "results_file = '_CATBDiff_EFFLOO_' + str(number_active_points)   # index for results files\n",
    "\n",
    "for experiments in range(number_experiments):\n",
    "    print('Experiment: ', experiments+1 , '#################################################################' )\n",
    "    \n",
    "    ActiveTrain_1 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "    ActiveTrain_2 = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "\n",
    "    #INITIAL design of experiments (LHS) passive training ####################################\n",
    "\n",
    "    n = 10       # number of initial sampling\n",
    "\n",
    "    xn = np.zeros((int(n), dim))      #normalized training points\n",
    "    xr = np.zeros((int(n), dim))      #scaled training points\n",
    "    yn = np.zeros((int(n)))           #observations\n",
    "\n",
    "    # Check the variables limits for space-filling distribution\n",
    "    Xdoe = build.space_filling_lhs( {'x1':[-1, 1],      \n",
    "                                     'x2':[-1, 1],} , \n",
    "                                      num_samples = n )\n",
    "    #------------------------------------------------------------\n",
    "    xn[:,0] = Xdoe['x1']\n",
    "    xn[:,1] = Xdoe['x2']\n",
    "    xr[:,0] = PCK1.scalehermite(xn[:,0], x1mean, x1sigma)\n",
    "    xr[:,1] = PCK1.scalehermite(xn[:,1], x2mean, x2sigma)\n",
    "\n",
    "    yn_1 = function_1(xr)[0]\n",
    "    yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    # kernel hyperparameters-------------------------------------\n",
    "    v = 5/2        #Gaussian process\n",
    "    #truncation term-------------------------------------\n",
    "    p_max = 5  #for each variable â†’ same truncation , degree of expansion\n",
    "    \n",
    "    for points in range(number_active_points):\n",
    "\n",
    "        # Selecting the smallest e_loo model (length and order)\n",
    "        \n",
    "        mse_results = np.zeros(p_max-1)\n",
    "        opt_length_it = np.zeros(p_max-1)\n",
    "        eloo_results = np.zeros(p_max-1)\n",
    "\n",
    "        mean_loo = np.zeros(len(xn))\n",
    "        var_loo = np.zeros(len(xn))\n",
    "        sumat_1 = np.zeros((len(xn),(p_max-1)))\n",
    "        sumat_2 = np.zeros((len(xn),(p_max-1)))\n",
    "\n",
    "        dist = PCK1.distance(xn, xn)\n",
    "        lmax = np.max(dist)\n",
    "        lmin = np.min(dist[dist!=0])\n",
    "        bounds = [(lmin, lmax)]\n",
    "\n",
    "        results = dict()\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 1 #############################################\n",
    "    \n",
    "#         print('AT Limit state 1 ')\n",
    "\n",
    "        ModelName_1 = 'PCK1_' + str(len(xn))\n",
    "        \n",
    "        ModelName_1 = PC_Kriging(config)\n",
    "\n",
    "        # yn is changing for each LS (inside L_Object )\n",
    "        yn = yn_1    #observations\n",
    "        YN = YN_1    #test points\n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "\n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "            sumat_1[:,p-1] = np.divide(e_loo, var_loo)\n",
    "            \n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar1 = ModelName_1.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_1.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)    #selected based 'eloo' instead 'mse'\n",
    "        opt_1 = opt \n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar1 = ModelName_1.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        ## Pool of samples for MCS -----------------------------------\n",
    "        MCS_samples = 100000\n",
    "        LOOCV = np.zeros(MCS_samples)\n",
    "\n",
    "        MCinputs_norm = np.zeros((int(MCS_samples), dim))\n",
    "        MCinputs = np.zeros((int(MCS_samples), dim))\n",
    "\n",
    "        MCinputs_norm[:,0] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "        MCinputs_norm[:,1] = np.random.normal(0, 1, size=int(MCS_samples))\n",
    "\n",
    "        MCinputs[:,0] = PCK1.scalehermite(MCinputs_norm[:,0], x1mean, x1sigma)  \n",
    "        MCinputs[:,1] = PCK1.scalehermite(MCinputs_norm[:,1], x2mean, x2sigma)  \n",
    "    \n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_1 = function_1(MCinputs)[0]  \n",
    "        fail_samples_1 = np.sum(ymc_1 < 0 )\n",
    "        Pf_ref_1 = fail_samples_1 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_1, varMC_1 = ModelName_1.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_1 = np.sum(np.asarray(meanMC_1) < 0 )\n",
    "        fail_prob_SUMO_1 = fail_samples_SUMO_1 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_1 ) / (fail_prob_SUMO_1 * MCS_samples) )\n",
    "\n",
    "        print('LS1: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results), 'Pf_ref', Pf_ref_1 ,'Pf', fail_prob_SUMO_1 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_1[str(len(xn))+'points'] = ModelName_1 , fail_prob_SUMO_1 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "        \n",
    "        # ##############################################################################\n",
    "        # Active training of Limit State 2 #############################################\n",
    "        \n",
    "#         print('Training Limit state 2 ')\n",
    "        \n",
    "        ModelName_2 = 'PCK2_' + str(len(xn))\n",
    "        \n",
    "        ModelName_2 = PC_Kriging(config)\n",
    "        \n",
    "        # yn is changing for each LS \n",
    "        yn = yn_2\n",
    "        YN = YN_2\n",
    "        # Selecting the smallest e_loo model (length and order) \n",
    "\n",
    "        # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        for p in range(1, p_max):\n",
    "            \n",
    "            # results = dict()\n",
    "            # bounds = [(lmin, lmax)]\n",
    "            \n",
    "            results['shgo'] = optimize.shgo(L_Object, bounds)\n",
    "            opt_length = results['shgo']['x'][0]\n",
    "\n",
    "            theta = np.array([opt_length, v])\n",
    "\n",
    "            #Generating PCK models for each reduced design of experiments \n",
    "\n",
    "            for i in range (0, len(xn) ):\n",
    "\n",
    "                yn_loo= np.delete(yn,[i])                            #y_n-i      leaving element i out the observations \n",
    "                xr_loo= np.delete(xr,[i*2,i*2+1]).reshape(-1,dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                xn_loo= np.delete(xn,[i*2,i*2+1]).reshape(-1,dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                #training LOO\n",
    "                modelpar_loo = PCK_loo.train (xn_loo , yn_loo , p , theta )\n",
    "\n",
    "                #predicting LOO over each removed sample\n",
    "                mean_loo[i], var_loo[i] = PCK_loo.predict_fast(xn[i].reshape(1,-1))\n",
    "\n",
    "            e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "            sumat_2[:,p-1] = np.divide(e_loo, var_loo)\n",
    "            eloo_results[p-1] = e_loo\n",
    "\n",
    "            #--------------------------------------- error over a set of test points\n",
    "            modelpar2 = ModelName_2.train (xn, yn, p, theta) \n",
    "            mean0, var0 = ModelName_2.predict_fast(XN)    # test points predictions mean, variance\n",
    "\n",
    "            mse = np.mean ((YN - mean0)**2)\n",
    "\n",
    "            mse_results[p-1] = mse\n",
    "            opt_length_it[p-1] = opt_length\n",
    "\n",
    "    #         print('Degree', p, 'MSE', \"%.2f\" % round(mse, 2) , 'e_LOO', \"%.5f\" % e_loo)\n",
    "\n",
    "        ## training optimal model ----------------------------\n",
    "\n",
    "        opt = np.argmin(eloo_results)\n",
    "        opt_2 = opt  \n",
    "        theta_opt = np.array([opt_length_it[opt], v]) \n",
    "\n",
    "        modelpar2 = ModelName_2.train (xn, yn, int(opt+1), theta_opt) \n",
    "\n",
    "        # Pf estimation ----------------------------------------------\n",
    "        \n",
    "            # ground truth ls\n",
    "        ymc_2 = function_2(MCinputs)[0]  \n",
    "        fail_samples_2 = np.sum(ymc_2 < 0 )\n",
    "        Pf_ref_2 = fail_samples_2 / MCS_samples\n",
    "        \n",
    "            # surrogate ls\n",
    "        meanMC_2, varMC_2 = ModelName_2.predict_fast(MCinputs_norm)    # mean, variance\n",
    "        fail_samples_SUMO_2 = np.sum(np.asarray(meanMC_2) < 0 )\n",
    "        fail_prob_SUMO_2 = fail_samples_SUMO_2 / MCS_samples\n",
    "\n",
    "        cov_pf = np.sqrt((1 - fail_prob_SUMO_2 ) / (fail_prob_SUMO_2 * MCS_samples) )        \n",
    "        \n",
    "        print('LS2: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results) , 'Pf_ref', Pf_ref_2 ,'Pf', fail_prob_SUMO_2 , 'CoV', \"%.5f\" % round(cov_pf, 4))\n",
    "\n",
    "        #saving results ----------------------------\n",
    "\n",
    "        ActiveTrain_2[str(len(xn))+'points'] = ModelName_2 , fail_prob_SUMO_2 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "\n",
    "        # ##############################################################################\n",
    "                \n",
    "        if ( points == 0 ):   \n",
    "            meanMC = meanMC_1\n",
    "            varMC = varMC_1\n",
    "            sumat = sumat_1\n",
    "            opt = opt_1                 \n",
    "            print ('LS 1')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        elif ( fail_prob_SUMO_1 == 0 ): \n",
    "            meanMC = meanMC_1\n",
    "            varMC = varMC_1\n",
    "            sumat = sumat_1\n",
    "            opt = opt_1                 \n",
    "            print ('LS 1')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        elif ( fail_prob_SUMO_2 == 0 ): \n",
    "            meanMC = meanMC_2\n",
    "            varMC = varMC_2\n",
    "            sumat = sumat_2\n",
    "            opt = opt_2                 \n",
    "            print ('LS 2')\n",
    "\n",
    "            Pf1_old = fail_prob_SUMO_1\n",
    "            Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "        else:\n",
    "            Pf1_new = fail_prob_SUMO_1\n",
    "            Pf2_new = fail_prob_SUMO_2\n",
    "\n",
    "            B1_old = - norm.ppf ( Pf1_old )\n",
    "            B2_old = - norm.ppf ( Pf2_old )\n",
    "\n",
    "            B1_new = - norm.ppf ( Pf1_new )\n",
    "            B2_new = - norm.ppf ( Pf2_new )\n",
    "\n",
    "            B_error1 = abs(B1_old - B1_new ) / B1_old\n",
    "            B_error2 = abs(B2_old - B2_new ) / B2_old\n",
    "\n",
    "            if (B_error1 > B_error2):\n",
    "\n",
    "                meanMC = meanMC_1\n",
    "                varMC = varMC_1\n",
    "                sumat = sumat_1\n",
    "                opt = opt_1                 \n",
    "                print (B_error1, B_error2, 'LS 1')\n",
    "\n",
    "                Pf1_old = fail_prob_SUMO_1\n",
    "                Pf2_old = fail_prob_SUMO_2\n",
    "\n",
    "            else:\n",
    "\n",
    "                meanMC = meanMC_2\n",
    "                varMC = varMC_2\n",
    "                sumat = sumat_2\n",
    "                opt = opt_2                 \n",
    "                print (B_error1, B_error2, 'LS 2')\n",
    "\n",
    "                Pf1_old = fail_prob_SUMO_1\n",
    "                Pf2_old = fail_prob_SUMO_2\n",
    "                \n",
    "        # LOO CV errors ###################################################\n",
    "        #variance enhancement based LOO CV erros around voronoi cells\n",
    "        for k in range (0, MCS_samples):               \n",
    "            voro = VoronoiCell(MCinputs[k], xr)\n",
    "            LOOCV[k]= varMC[k]*(1+sumat[voro, opt])     \n",
    "\n",
    "        ### Evaluating new points\n",
    "        eff = EFF(meanMC.reshape(-1), LOOCV.reshape(-1) , 0 )  #(mean, variance, target) \n",
    "        \n",
    "        xr = np.append(xr, MCinputs[np.argmax(eff)]).reshape(-1,2)\n",
    "        xn = np.append(xn, MCinputs_norm[np.argmax(eff)]).reshape(-1,2)\n",
    "\n",
    "        yn_1 = function_1(xr)[0]\n",
    "        yn_2 = function_2(xr)[0]\n",
    "    \n",
    "    \n",
    "        print('number of training points: ', len(xn),'-------------------------------------------------')\n",
    "    filename1 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS1.sav'\n",
    "\n",
    "    pickle.dump(ActiveTrain_1, open(filename1, 'wb'))\n",
    "    \n",
    "    filename2 = 'Batch_'+ str(experiments+1) + results_file + 'p_LS2.sav'\n",
    "    pickle.dump(ActiveTrain_2, open(filename2, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcaf520de8922068463cfafc41a7750ae3c51c1c987bfba8ad58100498b05857"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
