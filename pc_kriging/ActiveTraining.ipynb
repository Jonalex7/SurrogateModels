{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pc_kriging import PC_Kriging\n",
    "from datetime import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from doepy import build\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import pickle\n",
    "\n",
    "class Active_Training():\n",
    "\n",
    "    def __init__(self, model=None, settings=None):\n",
    "        if model is None:\n",
    "            model = {\"metamodel\" : 'PCK'}\n",
    "        assert \"metamodel\" in model and \\\n",
    "            \"Missing model type\"\n",
    "        \n",
    "        self.date_record = datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "\n",
    "        #----------------------------------------------------------------------\n",
    "        self.doe_limits = {}              #dict with marginals limits (for initial sampling)\n",
    "        self.config, poly_type = {}, []\n",
    "        self.marginals = settings[\"marginals_R\"][0]\n",
    "        \n",
    "        self.dim = len(settings[\"marginals_R\"][0])      #Input dimensions\n",
    "        self.n_act = settings[\"active_sampling\"][0]     #Number of active samples\n",
    "        self.passive_strat = settings[\"passive_sampling\"][1]\n",
    "        self.n_o = settings[\"passive_sampling\"][0]\n",
    "\n",
    "        self.MaternCoef = settings[\"model\"][0]\n",
    "        self.p_max = settings[\"model\"][1]\n",
    "        self.ModelType = model[\"metamodel\"]\n",
    "        self.targetF = settings[\"active_sampling\"][1]\n",
    "        self.learningF = settings[\"active_sampling\"][2]\n",
    "        #----------------------------------------------------------------------\n",
    "        for margin in range (0, self.dim):\n",
    "            self.doe_limits['x' + str (margin + 1)] = [-1, 1]  \n",
    "            poly_type.append(settings[\"marginals_R\"][0]['x' + str (margin + 1)][2])\n",
    "\n",
    "        self.config[\"pol_type\"] = poly_type\n",
    "\n",
    "        #----------------------------------------------------------------------\n",
    "        if self.ModelType == 'PCK':\n",
    "            \n",
    "            self.surrogate = PC_Kriging(self.config)\n",
    "            \n",
    "        # else we may add 'PCE' or 'Kriging' later\n",
    "            \n",
    "\n",
    "    def passive_sampling (self, n):\n",
    "        \n",
    "        xn_o = np.zeros((n, self.dim))      #normalized samples\n",
    "        xr_o = np.zeros((n, self.dim))      #scaled samples\n",
    "        yn_o = np.zeros((n))           #observations\n",
    "        #----------------------------------------------------------------------\n",
    "        if  self.passive_strat == 'LHS':   #Latin hypercube sampling\n",
    "\n",
    "            Xdoe_N = build.space_filling_lhs( self.doe_limits , num_samples = n )\n",
    "        \n",
    "        # else WE SHOULD ADD 'RND' in case of random sampling on the marginals  \n",
    "        \n",
    "        #----------------------------------------------------------------------\n",
    "        # evaluation and isotransformation\n",
    "        \n",
    "        for margin in range (0, self.dim):\n",
    "            \n",
    "            xn_o[:, margin] = Xdoe_N['x' + str (margin + 1)]\n",
    "            \n",
    "            if self.config[\"pol_type\"][margin] == 'hermite':\n",
    "                mean_ = self.marginals['x' + str (margin + 1)][0]\n",
    "                var_ = self.marginals['x' + str (margin + 1)][1]\n",
    "                xr_o[:, margin] = self.surrogate.scalehermite( xn_o[:, margin], mean_, var_ )\n",
    "            else:\n",
    "                min_ = self.marginals['x' + str (margin + 1)][0]\n",
    "                max_ = self.marginals['x' + str (margin + 1)][1]\n",
    "                xr_o[:, margin] = self.surrogate.scalelegendre( xn_o[:, margin], min_, max_ )\n",
    "        \n",
    "        yn_o = self.targetF(xr_o)\n",
    "        \n",
    "        return xn_o, xr_o, yn_o  #returns initial sampling (normalized, scaled and R_evaluations)\n",
    "        \n",
    "\n",
    "    def active_sampling(self, MCpool, GroundT):\n",
    "        \n",
    "        experiment_results = {}   #results file { Surrogate , Pf, CoV_Pf , eLoo , mse }\n",
    "        \n",
    "        xn, xr, yn = self.passive_sampling(self.n_o)\n",
    "            \n",
    "        for points in range(self.n_act):\n",
    "\n",
    "            mse_results = np.zeros(self.p_max - 1)\n",
    "            opt_length_it = np.zeros(self.p_max - 1)\n",
    "            eloo_results = np.zeros(self.p_max - 1)\n",
    "\n",
    "            mean_loo = np.zeros(len(xn))\n",
    "            var_loo = np.zeros(len(xn))\n",
    "            sumat = np.zeros((len(xn),(self.p_max - 1)))\n",
    "\n",
    "            # OPTIMAL SURROGATE MODEL -----------------------------------\n",
    "        \n",
    "            for p in range(1, self.p_max):\n",
    "                \n",
    "                d = self.surrogate.distance(xn, xn)\n",
    "                lmin = np.min(d[d!=0])\n",
    "                \n",
    "                ModelParam_temp = self.surrogate.train(xn, yn, p, lmin, self.MaternCoef)\n",
    "                \n",
    "                opt_length = self.surrogate.optimize('shgo')\n",
    "            \n",
    "                if self.ModelType == 'PCK':\n",
    "\n",
    "                    self.surrogate_loo = PC_Kriging(self.config)    # for LOOCV with same 'config' as specified in the original model\n",
    "\n",
    "                for out in range (0, len(xn)):\n",
    "\n",
    "                    yn_loo= np.delete(yn,[out])                                     #y_n-i      leaving element i out the observations \n",
    "                    xr_loo= np.delete(xr,[out*2, out*2+1]).reshape(-1, self.dim)    #x1r_n-i   leaving element i out the inputs (xr)\n",
    "                    xn_loo= np.delete(xn,[out*2, out*2+1]).reshape(-1, self.dim)    #x_n-i     leaving element i out the nomalized inputs (xn)\n",
    "\n",
    "                    #training LOO\n",
    "                    modelpar_loo = self.surrogate_loo.train(xn_loo , yn_loo , p , opt_length, self.MaternCoef)\n",
    "\n",
    "                    #predicting LOO over each removed sample\n",
    "                    mean_loo[out], var_loo[out] = self.surrogate_loo.predict_fast(xn[out].reshape(1, -1))\n",
    "\n",
    "                e_loo = np.mean (yn - mean_loo)**2              #LOO CV squared errors\n",
    "                \n",
    "                sumat[:,p-1] = np.divide(e_loo, var_loo)\n",
    "                \n",
    "                eloo_results[p-1] = e_loo\n",
    "                opt_length_it[p-1] = opt_length \n",
    "            #--------------------------------------- Gen. error over a set of test points\n",
    "#                 mean0, var0 = self.surrogate.predict_fast(XN)    # test points predictions mean, variance\n",
    "#                 mse = np.mean ((YN - mean0)**2)\n",
    "#                 mse_results[p-1] = mse\n",
    "\n",
    "            ## training optimal model ----------------------------\n",
    "\n",
    "            opt = np.argmin(eloo_results)    #selected based 'eloo'\n",
    "\n",
    "            ModelParam = self.surrogate.train (xn, yn, int(opt+1), opt_length_it[opt], self.MaternCoef)\n",
    "            \n",
    "            MCinputs_norm = np.zeros((int(MCpool), self.dim))\n",
    "            MCinputs = np.zeros((int(MCpool), self.dim))\n",
    "            LOOCV = np.zeros(int(MCpool))\n",
    "            \n",
    "            ## Generating pool of samples - MCS -----------------------------------\n",
    "\n",
    "            for margin in range (0, self.dim):\n",
    "\n",
    "                if self.config[\"pol_type\"][margin] == 'hermite':\n",
    "                    \n",
    "                    MCinputs_norm[:, margin] = np.random.normal(0, 1, size=int(MCpool))\n",
    "                    \n",
    "                    mean_ = self.marginals['x' + str (margin + 1)][0]\n",
    "                    var_ = self.marginals['x' + str (margin + 1)][1]\n",
    "                    \n",
    "                    MCinputs[:, margin] = self.surrogate.scalehermite( MCinputs_norm[:, margin], mean_, var_ )\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    MCinputs_norm[:, margin] = np.random.uniform(-1, 1, size=int(MCpool))\n",
    "                    \n",
    "                    min_ = self.marginals['x' + str (margin + 1)][0]\n",
    "                    max_ = self.marginals['x' + str (margin + 1)][1]\n",
    "                    \n",
    "                    MCinputs[:, margin] = self.surrogate.scalelegendre( MCinputs_norm[:, margin], min_, max_ )\n",
    "            \n",
    "            # Pf estimation ----------------------------------------------\n",
    "            \n",
    "            meanMC, varMC = self.surrogate.predict_fast(MCinputs_norm)    # mean, variance\n",
    "            fail_samples_SUMO = np.sum(np.asarray(meanMC) < 0 )\n",
    "            Pf_SUMO = fail_samples_SUMO / MCpool\n",
    "            \n",
    "            if GroundT == 'True':\n",
    "                yMC_ref = self.targetF(MCinputs)  \n",
    "                fail_samples_ref = np.sum(yMC_ref < 0 )\n",
    "                Pf_Ref = fail_samples_ref / MCpool\n",
    "                \n",
    "            else:\n",
    "                Pf_ref = 'NoRef_Pf'\n",
    "            \n",
    "            cov_pf = np.sqrt((1 - fail_prob_SUMO ) / (fail_prob_SUMO * MCpool) )\n",
    "\n",
    "            print('LS: ','Degree', int(opt+1), 'e_LOO', np.min(eloo_results), 'Pf_ref',\n",
    "                  Pf_ref ,'Pf_SuMo', fail_prob_SUMO_1 , 'CoV_SuMo', \"%.5f\" % round(cov_pf, 4))\n",
    "            \n",
    "            # Saving results ----------------------------\n",
    "\n",
    "#             experiment_results[str(len(xn))+'points'] = ModelName_1 , fail_prob_SUMO_1 , cov_pf , np.min(eloo_results), np.min(mse_results)\n",
    "\n",
    "            # Learning Function ----------------------------\n",
    "    \n",
    "            if self.learningF == 'U' :\n",
    "                U_f = sef.U_function(meanMC.reshape(-1), varMC.reshape(-1))\n",
    "                xr = np.append(xr, MCinputs[np.argmin(U_f)]).reshape(-1,2)\n",
    "                xn = np.append(xn, MCinputs_norm[np.argmin(U_f)]).reshape(-1,2)\n",
    "                \n",
    "            elif self.learningF == 'EFF':\n",
    "                eff = self.EFF(meanMC.reshape(-1),varMC.reshape(-1), 0)\n",
    "                xr = np.append(xr, MCinputs[np.argmax(eff)]).reshape(-1,2)\n",
    "                xn = np.append(xn, MCinputs_norm[np.argmax(eff)]).reshape(-1,2)\n",
    "            \n",
    "            # LOO CV errors ###################################################\n",
    "            #variance modification based LOO CV erros around voronoi cells\n",
    "            \n",
    "            elif self.learningF == 'ULOO' :\n",
    "                for k in range (0, MCpool):               \n",
    "                    voro = self.VoronoiCell(MCinputs[k], xr)\n",
    "                    LOOCV[k]= varMC[k] * (1 + sumat[voro, opt])\n",
    "                \n",
    "                U_f = sef.U_function(meanMC.reshape(-1), LOOCV.reshape(-1))\n",
    "                xr = np.append(xr, MCinputs[np.argmin(U_f)]).reshape(-1,2)\n",
    "                xn = np.append(xn, MCinputs_norm[np.argmin(U_f)]).reshape(-1,2)\n",
    "                \n",
    "            elif self.learningF == 'EFFLOO' :\n",
    "                for k in range (0, MCpool):               \n",
    "                    voro = self.VoronoiCell(MCinputs[k], xr)\n",
    "                    LOOCV[k]= varMC[k]*(1 + sumat[voro, opt])\n",
    "                \n",
    "                eff = self.EFF(meanMC.reshape(-1),varMC.reshape(-1), 0)\n",
    "                xr = np.append(xr, MCinputs[np.argmax(eff)]).reshape(-1,2)\n",
    "                xn = np.append(xn, MCinputs_norm[np.argmax(eff)]).reshape(-1,2)\n",
    "            \n",
    "            else:\n",
    "                print ('No learning metric speficied')\n",
    "\n",
    "    def EFF(self, u, v, z):\n",
    "        zl=-2*v\n",
    "        zh=2*v\n",
    "        return ((u-z)*( 2*norm.cdf((z-u)/v) - norm.cdf((zl-u)/v) - norm.cdf((zh-u)/v)) \n",
    "                -(v)*( 2*norm.pdf((z-u)/v) - norm.pdf((zl-u)/v) - norm.pdf((zh-u)/v))  \n",
    "                +(2*v)*(norm.cdf((zh-u)/v) - norm.cdf((zl-u)/v)))\n",
    "    \n",
    "    def U_function(self, u, v):\n",
    "        return np.abs(u)/v\n",
    "    \n",
    "    def VoronoiCell(self, x,xn):   #given x [single value] return the index of the closest xn [array]\n",
    "        dist = self.surrogate.distance(x.reshape(1,-1),xn)\n",
    "        return np.argmin(dist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS1(x):                   #Definition of target limit state\n",
    "    return x*np.sin(x)\n",
    "\n",
    "model = {\"metamodel\" : 'PCK'}\n",
    "training_settings = {\"passive_sampling\" : [10,'LHS'] , # initial samplings [n, dim, method]\n",
    "                     \"marginals_R\" : [{'x1':[0, 15, 'legendre'], 'x2':[3, 1.5, 'hermite']}],   # {'x1':[Min, Max], 'x2':[mean, var]}  ( if Legendre , if Hermite)\n",
    "                     \"active_sampling\" : [2, LS1, 'U'], #target settings [n_act, targetF, learningF]\n",
    "                     \"model\": [5/2, 5]}                  #modelparameters, matern coeff, max polynomial degree\n",
    "\n",
    "PCK_batches = Active_Training(model, training_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PCK_batches.active_sampling(1000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr1 = np.array( [9.60173493460726,\n",
    "14.0942931914357,\n",
    "13.3422784718819,\n",
    "6.92708483258534,\n",
    "4.44528591511115,\n",
    "7.66438265483689,\n",
    "0.0286187144815328,\n",
    "5.91008701677294,\n",
    "10.6641810829072,\n",
    "2.13464775089995]).reshape(-1,1)\n",
    "\n",
    "xn1 = PCK1.surrogate.LinearNorm(xr1, 0.0, 15.0, -1.0, 1.0)\n",
    "\n",
    "y1 = LS1(xr1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
